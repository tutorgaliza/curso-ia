{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Curso B\u00e1sico de Inteligencia Artificial (IA)","text":"<p>Este curso te llevar\u00e1 desde los conceptos fundamentales de la inteligencia artificial hasta los temas m\u00e1s avanzados, como el aprendizaje profundo y los modelos de lenguaje de gran escala (LLMs). El contenido est\u00e1 organizado en un orden progresivo, para que puedas comprender c\u00f3mo cada t\u00e9cnica construye sobre las anteriores.</p>"},{"location":"#1-introduccion-a-la-inteligencia-artificial","title":"1. Introducci\u00f3n a la inteligencia artificial","text":""},{"location":"introduction/","title":"Introducci\u00f3n a la Inteligencia Artificial (IA)","text":""},{"location":"introduction/#1-que-es-la-inteligencia-artificial","title":"1. \u00bfQu\u00e9 es la Inteligencia Artificial?","text":""},{"location":"introduction/#11-definicion","title":"1.1 Definici\u00f3n","text":"<p>La inteligencia artificial (IA) La inteligencia artificial es un campo de la ciencia relacionado con la creaci\u00f3n de ordenadores y m\u00e1quinas que pueden razonar, aprender y actuar de una forma que normalmente necesitar\u00eda inteligencia humana o que consuma datos cuya escala supere lo que las personas pueden analizar. </p> <p>La IA es un campo amplio que abarca muchas disciplinas diferentes, como la inform\u00e1tica, estad\u00edstica y anal\u00edtica de datos, ingenier\u00eda de hardware y software, ling\u00fc\u00edstica, neurociencia e incluso filosof\u00eda y psicolog\u00eda. </p> <p>A nivel operativo para el uso empresarial, la IA es un conjunto de tecnolog\u00edas basadas principalmente en aprendizaje autom\u00e1tico y aprendizaje profundo, que se usan para anal\u00edticas de datos, predicciones y previsiones, categorizaci\u00f3n de objetos, procesamiento del lenguaje natural, recomendaciones, recuperaci\u00f3n inteligente de datos y mucho m\u00e1s. Es por tanto, simulaci\u00f3n de procesos humanos por parte de m\u00e1quinas, especialmente sistemas inform\u00e1ticos. Estos procesos incluyen el aprendizaje (adquirir informaci\u00f3n y reglas para usarla), el razonamiento (usar reglas para llegar a conclusiones aproximadas o definidas) y la autocorrecci\u00f3n. Existen diferentes niveles y tipos de IA seg\u00fan su capacidad y funcionalidad.</p>"},{"location":"introduction/#12-como-funciona-la-ia","title":"1.2 \u00bfC\u00f3mo funciona la IA?","text":"<p>Aunque los detalles var\u00edan seg\u00fan las t\u00e9cnicas de IA, el principio fundamental gira en torno a los datos. Los sistemas de IA aprenden y mejoran a trav\u00e9s de la exposici\u00f3n a grandes cantidades de datos, identificando patrones y relaciones que los humanos pueden pasar por alto.</p> <p>Este proceso de aprendizaje a menudo implica algoritmos, que son conjuntos de reglas o instrucciones que gu\u00edan el an\u00e1lisis y la toma de decisiones de la IA. En el aprendizaje autom\u00e1tico, un subconjunto popular de IA, los algoritmos se entrenan con datos etiquetados o sin etiquetar para hacer predicciones o categorizar informaci\u00f3n. </p> <p>El aprendizaje profundo, otra especializaci\u00f3n, utiliza redes neuronales artificiales con varias capas para procesar la informaci\u00f3n, imitando la estructura y la funci\u00f3n del cerebro humano. Gracias al aprendizaje y la adaptaci\u00f3n continuos, los sistemas de IA son cada vez m\u00e1s expertos en realizar tareas espec\u00edficas, desde reconocer im\u00e1genes hasta traducir idiomas, etc.</p>"},{"location":"introduction/#2-clasificacion-de-la-ia-por-capacidades","title":"2. Clasificaci\u00f3n de la IA por Capacidades","text":""},{"location":"introduction/#21-ia-estrecha-o-debil","title":"2.1 IA Estrecha o D\u00e9bil","text":"<p>La IA Estrecha (tambi\u00e9n llamada IA d\u00e9bil) se refiere a sistemas dise\u00f1ados para realizar una tarea espec\u00edfica. Estos sistemas no tienen consciencia, conocimiento general ni capacidades m\u00e1s all\u00e1 de su tarea espec\u00edfica. Se considera inteligencia limitada porque solo puede llevar a cabo conjuntos de acciones delimitados por su programaci\u00f3n y entrenamiento  Ejemplos incluyen: - Asistentes virtuales (Siri, Alexa) - Motores de b\u00fasqueda - Sistemas de recomendaci\u00f3n</p>"},{"location":"introduction/#22-ia-general-o-fuerte","title":"2.2 IA General o Fuerte","text":"<p>La IA General es te\u00f3rica por ahora y se refiere a una IA que puede realizar cualquier tarea cognitiva que un ser humano puede realizar. Una IA General puede aprender de sus experiencias y aplicar ese conocimiento en nuevas situaciones. Ser\u00eda la capacidad de una m\u00e1quina para \"sentir, pensar y actuar\" como lo har\u00eda una persona. Actualmente, la AGI no existe</p>"},{"location":"introduction/#23-ia-superinteligente","title":"2.3 IA Superinteligente","text":"<p>La IA Superinteligente va m\u00e1s all\u00e1 de la inteligencia humana en todos los aspectos. Ser\u00eda capaz de resolver problemas mucho m\u00e1s complejos de lo que los humanos pueden, tomando decisiones con una capacidad y velocidad incomparables. Esta IA a\u00fan es hipot\u00e9tica.</p>"},{"location":"introduction/#3-clasificacion-de-la-ia-por-funcionalidad","title":"3. Clasificaci\u00f3n de la IA por Funcionalidad","text":""},{"location":"introduction/#31-ia-reactiva","title":"3.1 IA Reactiva","text":"<p>La IA Reactiva es la m\u00e1s b\u00e1sica de todas. No tiene memoria y solo responde a est\u00edmulos en tiempo real que ya tiene preprogramadas. Un buen ejemplo de IA reactiva es Deep Blue, el sistema de ajedrez de IBM que venci\u00f3 a Garry Kasparov. No utiliza memoria y, por lo tanto, no puede aprender con datos nuevos. Solo analiza las jugadas actuales sin considerar experiencias previas.</p>"},{"location":"introduction/#32-ia-de-memoria-limitada","title":"3.2 IA de Memoria Limitada","text":"<p>La IA de Memoria Limitada es un paso adelante, ya que puede almacenar datos temporales para tomar decisiones basadas en experiencias recientes.  La IA m\u00e1s moderna se considera una memoria limitada. Puede usarla para mejorar con el tiempo entren\u00e1ndose con nuevos datos, normalmente a trav\u00e9s de una red neuronal artificial u otro modelo de entrenamiento. El aprendizaje profundo, un subconjunto del aprendizaje autom\u00e1tico, se considera inteligencia artificial de memoria limitada. Ejemplos comunes incluyen: - Veh\u00edculos aut\u00f3nomos: Los coches inteligentes pueden recordar la ubicaci\u00f3n de otros veh\u00edculos, se\u00f1ales de tr\u00e1fico y la velocidad para tomar decisiones m\u00e1s informadas.</p>"},{"location":"introduction/#33-ia-con-teoria-de-la-mente","title":"3.3 IA con Teor\u00eda de la Mente","text":"<p>Este tipo de IA es capaz de entender las emociones, creencias e intenciones de otros seres. Aunque todav\u00eda no se ha desarrollado completamente, es un \u00e1rea activa de investigaci\u00f3n. Se espera que permita interacciones m\u00e1s avanzadas entre humanos y m\u00e1quinas. Es una IA que puede emular la mente humana y que tiene funciones de toma de decisiones similares a las de una persona.</p>"},{"location":"introduction/#34-ia-autoconsciente","title":"3.4 IA Autoconsciente","text":"<p>La IA Autoconsciente es una IA avanzada que tendr\u00eda una forma de consciencia similar a la humana. Ser\u00eda capaz de entender su propia existencia, tener emociones y posiblemente incluso desarrollar una \u00e9tica.  Al igual que la IA de teor\u00eda de la mente, la consciente de s\u00ed misma no existe actualmente.</p>"},{"location":"introduction/#4-modelos-de-entrenamiento-de-aprendizaje-automatico","title":"4. Modelos de entrenamiento de Aprendizaje autom\u00e1tico","text":"<p>Cuando las empresas hablan de IA, a menudo hablan de \"datos de entrenamiento\". Pero \u00bfqu\u00e9 significa esto? Recuerda que la inteligencia artificial con memoria limitada es la IA que mejora con el tiempo al entrenarse con datos nuevos</p> <p>El aprendizaje autom\u00e1tico (Machine Learning) es un subconjunto de la IA que permite que las m\u00e1quinas aprendan de los datos sin ser expl\u00edcitamente programadas. Utiliza algoritmos para encontrar patrones en los datos y predecir resultados.</p>"},{"location":"introduction/#41-aprendizaje-supervisado","title":"4.1 Aprendizaje Supervisado","text":"<p>El aprendizaje supervisado  es un modelo de aprendizaje autom\u00e1tico que asigna una entrada espec\u00edfica a un resultado usando datos de entrenamiento etiquetados, despu\u00e9s el sistema debe aprender a predecir una salida a partir de una entrada espec\u00edfica. Ejemplos incluyen: - Clasificaci\u00f3n de im\u00e1genes (gatos vs perros) - Reconocimiento de voz - Diagn\u00f3sticos m\u00e9dicos</p>"},{"location":"introduction/#42-aprendizaje-no-supervisado","title":"4.2 Aprendizaje No Supervisado","text":"<p>En el aprendizaje no supervisado, el sistema recibe datos sin etiquetas y debe identificar patrones por s\u00ed mismo.  A diferencia del aprendizaje supervisado, el resultado final no se sabe con antelaci\u00f3n. En vez de eso, el algoritmo aprende de los datos y los clasifica en grupos seg\u00fan sus atributos. Por ejemplo, el aprendizaje no supervisado es bueno para identificar patrones coincidentes y definir modelos descriptivos. Se usa com\u00fanmente en: - Agrupamiento (clustering) de datos - Reducci\u00f3n de dimensionalidad - An\u00e1lisis de segmentaci\u00f3n de mercado</p>"},{"location":"introduction/#43-aprendizaje-mixto-o-semisupervisado","title":"4.3 Aprendizaje Mixto o Semisupervisado","text":"<p>Adem\u00e1s del aprendizaje supervisado y no supervisado, se suele emplear un enfoque mixto, llamado aprendizaje semisupervisado, en el que solo se etiquetan algunos datos. Aunque el resultado final del aprendizaje semisupervisado ya se conoce, el algoritmo tiene que saber c\u00f3mo organizar y estructurar los datos para lograr los resultados deseados. - LLM (Large Language Model)</p>"},{"location":"introduction/#44-aprendizaje-por-refuerzo","title":"4.4 Aprendizaje por Refuerzo","text":"<p>El aprendizaje por refuerzo entrena a un agente para tomar decisiones en un entorno, maximizando recompensas a lo largo del tiempo. Es decir, es un modelo de aprendizaje autom\u00e1tico que se puede describir, en l\u00edneas generales, como \"aprender con la pr\u00e1ctica\". Un \"agente\" aprende a llevar a cabo una tarea definida mediante ensayo y error (un bucle de retroalimentaci\u00f3n) hasta que su rendimiento se encuentra dentro del intervalo deseado. El agente recibe refuerzo positivo cuando hace la tarea bien y refuerzo negativo cuando falla. Se utiliza mucho en rob\u00f3tica, juegos y control aut\u00f3nomo. Ejemplos incluyen: - Drones - Juegos como AlphaGo de Google DeepMind</p>"},{"location":"introduction/#5-deep-learning-aprendizaje-profundo","title":"5. Deep Learning (Aprendizaje Profundo)","text":"<p>El Deep Learning es un subconjunto del aprendizaje autom\u00e1tico que utiliza redes neuronales profundas para identificar patrones en grandes cantidades de datos. </p> <p>Una red neuronal es un sistema de neuronas artificiales, a veces llamadas \"perceptrones\", que son nodos computacionales que se usan para clasificar y analizar datos. Los datos se ingieren en la primera capa de una red neuronal, cada uno de los perceptrones toma una decisi\u00f3n y, a continuaci\u00f3n, transmite esa informaci\u00f3n a varios nodos en la siguiente capa. Los modelos de entrenamiento con m\u00e1s de tres capas se denominan \"redes neuronales profundas\" o \"aprendizaje profundo\". Algunas redes neuronales modernas tienen cientos o miles de capas. El resultado de los perceptrones finales es llevar a cabo la tarea definida en la red neuronal, como clasificar un objeto o encontrar patrones en los datos. </p> <p>Aqu\u00ed est\u00e1n los principales tipos de redes neuronales utilizadas en Deep Learning:</p>"},{"location":"introduction/#tipos-de-redes-neuronales","title":"Tipos de Redes Neuronales","text":""},{"location":"introduction/#51-perceptron-1958","title":"5.1 Perceptr\u00f3n (1958)","text":"<ul> <li>A\u00f1o de Aparici\u00f3n: 1958</li> <li>Descripci\u00f3n: Introducido por Frank Rosenblatt, el perceptr\u00f3n es la forma m\u00e1s b\u00e1sica de red neuronal. Consiste en una \u00fanica capa de nodos (neuronas) que realiza clasificaciones binarias. Aunque es limitado en su capacidad (no puede resolver problemas no lineales como el XOR), sent\u00f3 las bases para el desarrollo de redes neuronales m\u00e1s complejas.</li> </ul>"},{"location":"introduction/#52-redes-neuronales-feedforward-redes-neuronales-de-alimentacion-directa-1960s","title":"5.2 Redes Neuronales Feedforward (Redes Neuronales de Alimentaci\u00f3n Directa) (1960s)","text":"<ul> <li>A\u00f1o de Aparici\u00f3n: 1960s</li> <li>Descripci\u00f3n: Las Redes Neuronales Feedforward (FF) son el tipo m\u00e1s b\u00e1sico de redes neuronales artificiales. En estas redes, la informaci\u00f3n fluye en una sola direcci\u00f3n, desde las capas de entrada hasta las capas de salida, sin ciclos ni conexiones recurrentes. Son ideales para tareas de clasificaci\u00f3n y regresi\u00f3n. Las redes neuronales de retroalimentaci\u00f3n suelen estar emparejadas con un algoritmo de correcci\u00f3n de errores llamado \"backpropagation\" que, a grandes rasgos, empieza por el resultado de la red neuronal y vuelve hasta el principio mientras detecta errores para mejorar la precisi\u00f3n de la red neuronal. Muchas redes neuronales sencillas pero potentes son de retroalimentaci\u00f3n profunda.</li> </ul>"},{"location":"introduction/#53-redes-neuronales-multicapa-multilayer-perceptron-mlp-1960s-1980s","title":"5.3 Redes Neuronales Multicapa (Multilayer Perceptron, MLP) (1960s-1980s)","text":"<ul> <li>A\u00f1o de Aparici\u00f3n: 1960s (concepto), popularizadas en 1980s</li> <li>Descripci\u00f3n: Las MLP consisten en m\u00faltiples capas de neuronas (entrada, ocultas y salida) y utilizan algoritmos de retropropagaci\u00f3n para el entrenamiento. Pueden resolver problemas no lineales y son la base de muchas arquitecturas modernas.</li> </ul>"},{"location":"introduction/#54-redes-neuronales-recurrentes-rnn-1980s","title":"5.4 Redes Neuronales Recurrentes (RNN) (1980s)","text":"<ul> <li>A\u00f1o de Aparici\u00f3n: 1980s</li> <li> <p>Descripci\u00f3n: Las RNN tienen conexiones recurrentes que permiten mantener una memoria interna de secuencias anteriores, lo que las hace ideales para tareas de procesamiento de secuencias como el reconocimiento de voz y el an\u00e1lisis de texto.</p> </li> <li> </li> <li> <p>A\u00f1o de Aparici\u00f3n: 1982</p> </li> <li> <p>Descripci\u00f3n: Introducidas por John Hopfield, estas redes son redes completamente conectadas y recurrentes utilizadas para la memoria asociativa y la optimizaci\u00f3n de problemas combinatorios.</p> </li> <li> </li> <li> <p>A\u00f1o de Aparici\u00f3n: 1985</p> </li> <li>Descripci\u00f3n: Propuestas por Geoffrey Hinton y Terry Sejnowski, las M\u00e1quinas de Boltzmann son redes estoc\u00e1sticas y recurrentes que pueden aprender distribuciones de probabilidad sobre sus entradas, utilizadas principalmente para el aprendizaje no supervisado.</li> </ul>"},{"location":"introduction/#541-redes-de-hopfield-hopfield-networks-1982","title":"5.4.1 Redes de Hopfield (Hopfield Networks) (1982)","text":""},{"location":"introduction/#542-maquinas-de-boltzmann-boltzmann-machines-1985","title":"5.4.2 M\u00e1quinas de Boltzmann (Boltzmann Machines) (1985)","text":""},{"location":"introduction/#55-redes-neuronales-convolucionales-cnn-1980s-1990s","title":"5.5 Redes Neuronales Convolucionales (CNN) (1980s-1990s)","text":"<ul> <li>A\u00f1o de Aparici\u00f3n: 1980s (concepto), popularizadas en 1998 con LeNet</li> <li>Descripci\u00f3n: Introducidas por Yann LeCun con la arquitectura LeNet para reconocimiento de d\u00edgitos escritos a mano. Las CNNs suelen usarse en el reconocimiento de im\u00e1genes y utilizan varias capas separadas (una capa convolucional y luego una capa de agrupaci\u00f3n) que filtran las diferentes partes de una imagen antes de volver a juntarlas (en la capa completamente conectada). Las primeras capas convolucionales pueden buscar elementos simples de una imagen, como colores y bordes, antes de buscar caracter\u00edsticas m\u00e1s complejas en capas adicionales.</li> </ul>"},{"location":"introduction/#56-autoencoders-1980s-desarrollados-mas-en-2000s","title":"5.6 Autoencoders (1980s, desarrollados m\u00e1s en 2000s)","text":"<ul> <li>A\u00f1o de Aparici\u00f3n: 1980s (concepto), avances significativos en 2000s</li> <li>Descripci\u00f3n: Los autoencoders son redes neuronales dise\u00f1adas para aprender representaciones compactas (codificaciones) de los datos de entrada, \u00fatiles para reducci\u00f3n de dimensionalidad, generaci\u00f3n de datos y preentrenamiento de redes profundas.</li> </ul>"},{"location":"introduction/#57-redes-neuronales-de-memoria-a-largo-y-corto-plazo-lstm-1997","title":"5.7 Redes Neuronales de Memoria a Largo y Corto Plazo (LSTM) (1997)","text":"<ul> <li>A\u00f1o de Aparici\u00f3n: 1997</li> <li>Descripci\u00f3n: Introducidas por Sepp Hochreiter y J\u00fcrgen Schmidhuber, son una forma avanzada de RNN que pueden usar la memoria para \"recordar\" lo que ha ocurrido en capas anteriores. La \u00fanica diferencia entre las RNNs y las LSTMs es que estas \u00faltimas pueden recordar lo que ocurri\u00f3 hace varias capas gracias al uso de celdas de memoria. Las LSTMs se suelen usar en el reconocimiento de voz y para hacer predicciones. </li> </ul>"},{"location":"introduction/#58-redes-generativas-antagonicas-gan-2014","title":"5.8 Redes Generativas Antag\u00f3nicas (GAN) (2014)","text":"<ul> <li>A\u00f1o de Aparici\u00f3n: 2014</li> <li>Descripci\u00f3n: Propuestas por Ian Goodfellow y sus colegas, las GAN consisten en dos redes  que compiten entre s\u00ed para generar datos sint\u00e9ticos realistas. Una red (la generadora) crea ejemplos que la otra red (la discriminadora) intenta demostrar si son verdaderos o falsos.  Han revolucionado la generaci\u00f3n de im\u00e1genes, s\u00edntesis de voz y creaci\u00f3n de contenido multimedia.</li> </ul>"},{"location":"introduction/#59-arquitectura-de-transformadores-transformers-2017","title":"5.9 Arquitectura de Transformadores (Transformers) (2017)","text":"<ul> <li>A\u00f1o de Aparici\u00f3n: 2017</li> <li>Descripci\u00f3n: Introducida en el art\u00edculo \"Attention is All You Need\" por Vaswani et al., la arquitectura de transformadores utiliza mecanismos de atenci\u00f3n para procesar datos en paralelo, superando a las RNN y CNN en tareas de procesamiento de lenguaje natural (NLP) y permitiendo la creaci\u00f3n de modelos m\u00e1s escalables.</li> </ul>"},{"location":"introduction/#510-modelos-de-lenguaje-grandes-llm-finales-de-2018-2020s","title":"5.10 Modelos de Lenguaje Grandes (LLM) (Finales de 2018-2020s)","text":"<ul> <li>A\u00f1o de Aparici\u00f3n: Finales de 2010s</li> <li>Descripci\u00f3n: Basados en la arquitectura de transformadores, los LLM como GPT (Generative Pre-trained Transformer), BERT (Bidirectional Encoder Representations from Transformers) y T5 (Text-To-Text Transfer Transformer) han alcanzado niveles avanzados en comprensi\u00f3n y generaci\u00f3n de lenguaje natural, siendo utilizados en una amplia variedad de aplicaciones como chatbots, traducci\u00f3n autom\u00e1tica y an\u00e1lisis de sentimientos.</li> </ul>"},{"location":"introduction/#511-redes-neuronales-transformer-avanzadas-y-multimodales-2020s","title":"5.11 Redes Neuronales Transformer Avanzadas y Multimodales (2020s)","text":"<ul> <li>A\u00f1o de Aparici\u00f3n: 2020s</li> <li>Descripci\u00f3n: Evoluciones de la arquitectura de transformadores que integran m\u00faltiples modalidades de datos (texto, im\u00e1genes, audio). Ejemplos incluyen CLIP de OpenAI, que combina procesamiento de im\u00e1genes con lenguaje, y modelos como DALL\u00b7E que generan im\u00e1genes a partir de descripciones textuales.</li> </ul>"},{"location":"introduction/#resumen-cronologico-de-tipos-de-redes-neuronales","title":"Resumen Cronol\u00f3gico de Tipos de Redes Neuronales","text":"A\u00f1o Tipo de Red Neuronal Descripci\u00f3n Breve 1958 Perceptr\u00f3n Red neuronal b\u00e1sica para clasificaci\u00f3n binaria. 1960s Redes Neuronales Feedforward (FF) Redes con flujo de informaci\u00f3n en una sola direcci\u00f3n, sin retroalimentaci\u00f3n. 1960s-1980s Redes Neuronales Multicapa (MLP) Redes con m\u00faltiples capas y retropropagaci\u00f3n para problemas no lineales. 1980s Redes Neuronales Recurrentes (RNN) Redes para procesamiento de secuencias con memoria interna. 1982 Redes de Hopfield Redes totalmente conectadas para memoria asociativa y optimizaci\u00f3n. 1985 M\u00e1quinas de Boltzmann Redes estoc\u00e1sticas para aprendizaje no supervisado. 1980s-1990s Redes Neuronales Convolucionales (CNN) Redes para extracci\u00f3n de caracter\u00edsticas espaciales en im\u00e1genes. 1980s-2000s Autoencoders Redes para aprendizaje de representaciones compactas de datos. 1997 LSTM RNN avanzadas para manejar dependencias a largo plazo. 2014 Redes Generativas Antag\u00f3nicas (GAN) Redes para generaci\u00f3n de datos sint\u00e9ticos realistas. 2017 Arquitectura de Transformadores (Transformers) Redes basadas en mecanismos de atenci\u00f3n para procesamiento paralelo. 2018-2020s Modelos de Lenguaje Grandes (LLM) Modelos basados en transformadores para comprensi\u00f3n y generaci\u00f3n de lenguaje. 2020s Redes Neuronales Transformer Avanzadas y Multimodales Modelos que integran m\u00faltiples tipos de datos (texto, im\u00e1genes, audio)."},{"location":"introduction/#-","title":"---","text":""},{"location":"introduction/#6-modelos-de-lenguaje-de-gran-tamano-llm","title":"6. Modelos de Lenguaje de Gran Tama\u00f1o (LLM)","text":"<p>Los Modelos de Lenguaje de Gran Tama\u00f1o (LLM, por sus siglas en ingl\u00e9s) han transformado el campo del procesamiento del lenguaje natural (NLP) al permitir que las m\u00e1quinas comprendan y generen texto humano de manera coherente y contextual. A continuaci\u00f3n, exploramos su origen, las arquitecturas que los sustentan, los principales modelos, su proceso de entrenamiento, aplicaciones y consideraciones \u00e9ticas.</p>"},{"location":"introduction/#que-son-los-llm","title":"\u00bfQu\u00e9 son los LLM?","text":"<p>Los LLM son modelos de inteligencia artificial que utilizan redes neuronales profundas para procesar y generar lenguaje humano. Est\u00e1n entrenados en enormes conjuntos de datos textuales, lo que les permite aprender patrones ling\u00fc\u00edsticos, sem\u00e1ntica y sintaxis del lenguaje natural. Basados en la arquitectura de Transformadores.</p>"},{"location":"introduction/#61-proceso-de-entrenamiento","title":"6.1 Proceso de Entrenamiento","text":"<ul> <li>Datos Masivos: Se entrenan con terabytes de texto que incluyen libros, art\u00edculos, sitios web y otros recursos.</li> <li>Aprendizaje mixto: Aprenden de manera aut\u00f3noma sin necesidad de etiquetado manual, mediante tareas como la predicci\u00f3n de la siguiente palabra en una oraci\u00f3n.</li> <li>Contexto y Coherencia: Gracias a su arquitectura, pueden mantener el contexto a lo largo de largas secuencias de texto, mejorando la coherencia en las respuestas.</li> <li>Fine-Tuning (Ajuste Fino): Despu\u00e9s del preentrenamiento, los modelos pueden ajustarse para tareas espec\u00edficas utilizando conjuntos de datos m\u00e1s peque\u00f1os y especializados.</li> </ul>"},{"location":"introduction/#62-relacion-entre-llm-y-transformers","title":"6.2 Relaci\u00f3n entre LLM y Transformers","text":"<p>Los Transformers han demostrado ser altamente efectivos para tareas de NLP, y la mayor\u00eda de los LLM modernos se basan en esta arquitectura. </p> <ul> <li>Eficiencia Computacional: Permiten entrenamiento en paralelo.</li> <li>Manejo de Contexto Extendido: Capturan relaciones a largo plazo en el texto.</li> <li>Flexibilidad: Adaptables a diversas tareas de NLP.</li> </ul>"},{"location":"introduction/#63-aplicaciones-de-los-llm","title":"6.3 Aplicaciones de los LLM","text":"<ul> <li>Asistentes Virtuales y Chatbots: Interacciones m\u00e1s naturales y contextuales.</li> <li>Traducci\u00f3n Autom\u00e1tica: Mejoras en precisi\u00f3n y fluidez.</li> <li>An\u00e1lisis de Sentimiento: Comprensi\u00f3n de percepciones del cliente en redes sociales.</li> <li>Generaci\u00f3n de Contenido: Creaci\u00f3n de res\u00famenes, art\u00edculos y textos personalizados.</li> <li>Educaci\u00f3n y Tutor\u00eda Personalizada: Proporcionan explicaciones y apoyo en el aprendizaje.</li> <li>Salud: Ayuda en diagn\u00f3stico preliminar y asistencia al paciente.</li> <li>Programaci\u00f3n: Generaci\u00f3n de c\u00f3digo y asistencia en desarrollo de software.</li> </ul>"},{"location":"introduction/#63-desafios-y-consideraciones-eticas","title":"6.3 Desaf\u00edos y Consideraciones \u00c9ticas","text":"<ul> <li>Sesgos y Discriminaci\u00f3n: Pueden heredar prejuicios de los datos de entrenamiento.</li> <li>Desinformaci\u00f3n: Capacidad para generar informaci\u00f3n falsa de manera convincente.</li> <li>Privacidad de Datos: Riesgo de reproducir informaci\u00f3n sensible.</li> <li>Recursos Computacionales: Alto consumo de energ\u00eda y recursos, impacto ambiental.</li> <li>Transparencia: Dificultad para entender y explicar las decisiones del modelo.</li> </ul>"},{"location":"introduction/#64-avances-y-tendencias-recientes","title":"6.4 Avances y Tendencias Recientes","text":"<ul> <li>Fine-Tuning Espec\u00edfico: Ajuste de modelos para tareas o dominios espec\u00edficos.</li> <li>Modelos Multimodales: Integraci\u00f3n de texto con im\u00e1genes y audio.</li> <li>Eficiencia y Sostenibilidad: Investigaci\u00f3n en arquitecturas m\u00e1s eficientes.</li> <li>Modelos Multiling\u00fces: Entrenamiento en m\u00faltiples idiomas para mayor accesibilidad.</li> <li>Aprendizaje Federado: Entrenamiento distribuido que mejora la privacidad.</li> </ul>"},{"location":"introduction/#65-impacto-en-la-sociedad-y-el-futuro","title":"6.5 Impacto en la Sociedad y el Futuro","text":"<p>Los LLM tienen el potencial de transformar sectores como:</p> <ul> <li>Educaci\u00f3n: Personalizaci\u00f3n del aprendizaje y acceso a informaci\u00f3n.</li> <li>Salud: Asistencia en diagn\u00f3sticos y tratamiento.</li> <li>Negocios: Automatizaci\u00f3n y mejora en atenci\u00f3n al cliente.</li> <li>Investigaci\u00f3n: An\u00e1lisis y s\u00edntesis de grandes vol\u00famenes de informaci\u00f3n.</li> </ul> <p>Consideraciones Futuras:</p> <ul> <li>Regulaci\u00f3n y \u00c9tica: Desarrollo de marcos para uso responsable.</li> <li>Accesibilidad: Democratizaci\u00f3n de la tecnolog\u00eda para evitar brechas.</li> <li>Interacci\u00f3n Humano-M\u00e1quina: Mejora en la comunicaci\u00f3n y colaboraci\u00f3n.</li> </ul>"},{"location":"introduction/#66-ejemplos-de-llm","title":"6.6 Ejemplos de LLM:","text":"<ul> <li> <p>ChatGPT (OpenAI): Es uno de los modelos m\u00e1s populares de OpenAI, basado en la arquitectura GPT (Generative Pre-trained Transformer). Se ha utilizado en diversas versiones como GPT-3 y GPT-4.</p> </li> <li> <p>Gemini (Google/Alphabet): Este es el nombre de los modelos de lenguaje de Google, que anteriormente estaba representado por Bard o el modelo de lenguaje de PaLM. Google ha reestructurado su enfoque hacia LLM con su proyecto Gemini, parte de su divisi\u00f3n de inteligencia artificial DeepMind.</p> </li> <li> <p>Claude (Anthropic): Claude es el modelo de lenguaje desarrollado por Anthropic, una empresa creada por antiguos miembros de OpenAI. Se centra en la seguridad y la alineaci\u00f3n de los modelos de IA.</p> </li> <li> <p>Copilot (Microsoft): Aunque Microsoft no desarrolla directamente su propio LLM, ha integrado modelos de OpenAI como GPT-4 en su ecosistema bajo el nombre de Copilot, que se utiliza en aplicaciones como Microsoft Word, Excel, y otras herramientas de productividad.</p> </li> <li> <p>LLaMA (Meta): El modelo LLaMA (Large Language Model Meta AI) es el LLM de Meta (Facebook), dise\u00f1ado para ser m\u00e1s eficiente en t\u00e9rminos de capacidad y rendimiento.</p> </li> </ul>"},{"location":"introduction/#7-redes-neuronales-multimodales","title":"7. Redes Neuronales Multimodales","text":""},{"location":"introduction/#71-que-son-las-redes-neuronales-multimodales","title":"7.1 \u00bfQu\u00e9 son las Redes Neuronales Multimodales?","text":"<p>Las Redes Neuronales Multimodales son arquitecturas avanzadas de inteligencia artificial dise\u00f1adas para procesar y combinar m\u00faltiples modalidades de datos simult\u00e1neamente, como texto, im\u00e1genes, audio y video. Su objetivo es integrar informaci\u00f3n de diferentes fuentes para realizar tareas m\u00e1s complejas y contextuales que requieren una comprensi\u00f3n hol\u00edstica de los datos.</p>"},{"location":"introduction/#72-caracteristicas-principales","title":"7.2 Caracter\u00edsticas Principales","text":"<ul> <li>Integraci\u00f3n de M\u00faltiples Modalidades: Capaces de manejar y fusionar distintos tipos de datos, permitiendo una comprensi\u00f3n m\u00e1s rica y completa.</li> <li>Espacios de Representaci\u00f3n Comunes: Transforman diferentes modalidades en representaciones vectoriales compatibles que pueden ser comparadas y combinadas en un espacio de embeddings unificado.</li> <li>Mecanismos de Atenci\u00f3n Multimodal: Utilizan mecanismos de atenci\u00f3n para alinear y relacionar informaci\u00f3n de diferentes modalidades de manera efectiva.</li> <li>Flexibilidad Arquitect\u00f3nica: Combinan diferentes tipos de redes neuronales, como Transformers para texto y Redes Convolucionales (CNN) para im\u00e1genes, adapt\u00e1ndose a las necesidades espec\u00edficas de cada tarea.</li> </ul>"},{"location":"introduction/#73-arquitectura-y-funcionamiento","title":"7.3 Arquitectura y Funcionamiento","text":""},{"location":"introduction/#731-componentes-de-las-redes-multimodales","title":"7.3.1 Componentes de las Redes Multimodales","text":"<ul> <li>Modelos de Texto: Utilizan arquitecturas basadas en Transformers para procesar y entender el lenguaje natural.</li> <li>Modelos de Imagen: Emplean Redes Neuronales Convolucionales (CNN) o arquitecturas de Transformers para extraer y comprender caracter\u00edsticas visuales.</li> <li>Modelos de Audio: Incorporan redes especializadas para el procesamiento de se\u00f1ales de audio, como Redes Neuronales Recurrentes (RNN) o Transformers adaptados.</li> <li>Integraci\u00f3n y Fusi\u00f3n: Las salidas de los distintos modelos se combinan en un espacio de representaci\u00f3n com\u00fan mediante capas de fusi\u00f3n que permiten la interacci\u00f3n entre las diferentes modalidades.</li> </ul>"},{"location":"introduction/#732-mecanismos-de-atencion-multimodal","title":"7.3.2 Mecanismos de Atenci\u00f3n Multimodal","text":"<p>Los mecanismos de atenci\u00f3n permiten que la red enfoque su atenci\u00f3n en partes relevantes de cada modalidad, alineando y relacionando informaci\u00f3n de manera contextual. Esto es crucial para tareas donde la relaci\u00f3n entre modalidades es compleja, como en la generaci\u00f3n de descripciones de im\u00e1genes o la respuesta a preguntas basadas en contenido visual.</p>"},{"location":"introduction/#74-aplicaciones-de-las-redes-neuronales-multimodales","title":"7.4 Aplicaciones de las Redes Neuronales Multimodales","text":"<p>7.4.1 Descripci\u00f3n de Im\u00e1genes</p> <p>Generar descripciones textuales detalladas basadas en el contenido de una imagen. Esto es \u00fatil para mejorar la accesibilidad de contenido visual y para aplicaciones de generaci\u00f3n de contenido autom\u00e1tico.</p> <p>7.4.2 Generaci\u00f3n de Im\u00e1genes a partir de Texto</p> <p>Crear im\u00e1genes realistas y detalladas a partir de descripciones textuales proporcionadas por el usuario. DALL\u00b7E de OpenAI es un ejemplo destacado de esta aplicaci\u00f3n.</p> <p>7.4.3 B\u00fasqueda Multimodal</p> <p>Realizar b\u00fasquedas que combinan texto e im\u00e1genes para obtener resultados m\u00e1s precisos y relevantes. Por ejemplo, buscar im\u00e1genes que correspondan a una descripci\u00f3n textual espec\u00edfica.</p> <p>7.4.4 Reconocimiento de Video y Audio</p> <p>Analizar y comprender contenido que involucra m\u00faltiples flujos de datos simult\u00e1neamente, como videos con subt\u00edtulos o transcripciones de audio.</p> <p>7.4.5 Asistentes Virtuales Avanzados</p> <p>Desarrollar asistentes que puedan interactuar de manera m\u00e1s rica y contextual, integrando comprensi\u00f3n de lenguaje natural con reconocimiento de im\u00e1genes o gestos.</p>"},{"location":"introduction/#75-ejemplos-notables-de-redes-neuronales-multimodales","title":"7.5 Ejemplos Notables de Redes Neuronales Multimodales","text":"<p>7.5.1 CLIP (Contrastive Language-Image Pre-training)</p> <p>Desarrollado por OpenAI, CLIP puede relacionar im\u00e1genes y texto de manera efectiva, permitiendo clasificar im\u00e1genes bas\u00e1ndose en descripciones textuales sin necesidad de entrenamiento espec\u00edfico para cada categor\u00eda.</p> <p>7.5.2 DALL\u00b7E</p> <p>Tambi\u00e9n de OpenAI, DALL\u00b7E genera im\u00e1genes a partir de descripciones textuales detalladas, combinando capacidades de generaci\u00f3n de texto e imagen para crear contenido visual innovador.</p> <p>7.5.3 GPT-4 Tambi\u00e9n de OpenAI,  GPT-4, en su versi\u00f3n multimodal, puede procesar tanto entradas de texto como de im\u00e1genes. Esto permite, por ejemplo, que el modelo entienda y describa im\u00e1genes, analice gr\u00e1ficos, o explique el contenido visual que se le presenta. En el caso de las im\u00e1genes, puede responder preguntas basadas en lo que \"ve\".</p>"},{"location":"introduction/#76-ventajas-de-las-redes-neuronales-multimodales","title":"7.6 Ventajas de las Redes Neuronales Multimodales","text":"<ul> <li>Comprensi\u00f3n Hol\u00edstica: Integran informaci\u00f3n de m\u00faltiples fuentes, proporcionando una visi\u00f3n m\u00e1s completa y contextualizada.</li> <li>Mayor Flexibilidad: Pueden adaptarse a tareas que requieren la interacci\u00f3n de diferentes tipos de datos, como la creaci\u00f3n de contenido creativo o la mejora de sistemas de b\u00fasqueda.</li> <li>Innovaci\u00f3n en Aplicaciones Creativas: Facilitan la generaci\u00f3n de contenido innovador y aplicaciones avanzadas en campos como el arte digital, la educaci\u00f3n y la investigaci\u00f3n.</li> </ul>"},{"location":"introduction/#77-desafios-de-las-redes-neuronales-multimodales","title":"7.7 Desaf\u00edos de las Redes Neuronales Multimodales","text":"<ul> <li>Complejidad de Entrenamiento: Requieren grandes conjuntos de datos multimodales y altos recursos computacionales para el entrenamiento.</li> <li>Integraci\u00f3n Efectiva de Modalidades: Lograr una alineaci\u00f3n efectiva entre diferentes tipos de datos puede ser complicado y requiere t\u00e9cnicas avanzadas.</li> <li>Sesgos Multimodales: Los sesgos presentes en una modalidad pueden afectar la comprensi\u00f3n general del modelo, requiriendo mecanismos de mitigaci\u00f3n de sesgos.</li> <li>Escalabilidad: Manejar y procesar m\u00faltiples tipos de datos de manera eficiente puede ser un desaf\u00edo a medida que aumenta la complejidad de las tareas.</li> <li>Mayor Complejidad Arquitect\u00f3nica: La integraci\u00f3n de m\u00faltiples modalidades a\u00f1ade una capa adicional de complejidad en comparaci\u00f3n con los LLM que manejan una sola modalidad.</li> <li>Requerimientos de Datos Multimodales: Necesitan conjuntos de datos que incluyan m\u00faltiples tipos de informaci\u00f3n, lo que puede ser m\u00e1s dif\u00edcil de obtener y procesar.</li> <li>Interacci\u00f3n entre Modalidades: Asegurar una interacci\u00f3n efectiva y significativa entre diferentes tipos de datos requiere t\u00e9cnicas avanzadas de alineaci\u00f3n y fusi\u00f3n.</li> </ul>"},{"location":"introduction/#78-conclusion","title":"7.8 Conclusi\u00f3n","text":"<p>Las Redes Neuronales Multimodales representan una evoluci\u00f3n significativa en el campo de la inteligencia artificial, permitiendo la integraci\u00f3n y comprensi\u00f3n simult\u00e1nea de m\u00faltiples tipos de datos. Esta capacidad de combinar diferentes modalidades de informaci\u00f3n abre nuevas posibilidades en diversas aplicaciones, desde la generaci\u00f3n de contenido creativo hasta la mejora de sistemas de b\u00fasqueda y asistentes virtuales avanzados.</p> <p>Aunque enfrentan desaf\u00edos en t\u00e9rminos de complejidad de entrenamiento, integraci\u00f3n de modalidades y gesti\u00f3n de sesgos, las ventajas que ofrecen en t\u00e9rminos de comprensi\u00f3n hol\u00edstica y flexibilidad hacen que las redes multimodales sean una \u00e1rea de investigaci\u00f3n y desarrollo prometedora. La continua innovaci\u00f3n en arquitecturas y t\u00e9cnicas de fusi\u00f3n multimodal permitir\u00e1 abordar estos desaf\u00edos, potenciando a\u00fan m\u00e1s el impacto de la inteligencia artificial en m\u00faltiples industrias.</p>"},{"location":"introduction/#8-procesamiento-de-lenguaje-natural-nlp-y-redes-neuronales","title":"8. Procesamiento de Lenguaje Natural (NLP) y Redes Neuronales","text":"<p>Aunque NLP no es una red neuronal en s\u00ed misma, se apoya en diversas arquitecturas de redes neuronales para llevar a cabo sus tareas. A continuaci\u00f3n, se detalla c\u00f3mo se integran diferentes tipos de redes neuronales en el campo de NLP:</p>"},{"location":"introduction/#redes-neuronales-feedforward-ff-en-nlp","title":"Redes Neuronales Feedforward (FF) en NLP","text":"<ul> <li>Aplicaci\u00f3n: Clasificaci\u00f3n de texto (e.g., detecci\u00f3n de spam, an\u00e1lisis de sentimientos).</li> <li>Descripci\u00f3n: Utilizadas para tareas donde se requiere una clasificaci\u00f3n simple basada en las caracter\u00edsticas extra\u00eddas del texto.</li> </ul>"},{"location":"introduction/#redes-neuronales-recurrentes-rnn-y-lstm-en-nlp","title":"Redes Neuronales Recurrentes (RNN) y LSTM en NLP","text":"<ul> <li>Aplicaci\u00f3n: Modelado de secuencias, generaci\u00f3n de texto, traducci\u00f3n autom\u00e1tica.</li> <li>Descripci\u00f3n: Capaces de manejar dependencias temporales en el texto, permitiendo una mejor comprensi\u00f3n del contexto.</li> </ul>"},{"location":"introduction/#arquitectura-de-transformadores-en-nlp","title":"Arquitectura de Transformadores en NLP","text":"<ul> <li>Aplicaci\u00f3n: Modelos de lenguaje grandes (LLM) como GPT, BERT, T5.</li> <li>Descripci\u00f3n: Utilizan mecanismos de atenci\u00f3n para procesar secuencias de texto de manera m\u00e1s eficiente y efectiva, permitiendo un mayor manejo del contexto y la generaci\u00f3n de texto coherente.</li> </ul>"},{"location":"introduction/#redes-generativas-antagonicas-gan-en-nlp","title":"Redes Generativas Antag\u00f3nicas (GAN) en NLP","text":"<ul> <li>Aplicaci\u00f3n: Generaci\u00f3n de texto realista, mejora de la calidad del texto generado.</li> <li>Descripci\u00f3n: Aunque menos comunes que en visi\u00f3n por computadora, las GAN pueden emplearse para generar texto variado y coherente.</li> </ul>"},{"location":"introduction/#conclusion","title":"Conclusi\u00f3n","text":"<p>Procesamiento de Lenguaje Natural (NLP) es un campo esencial dentro de la inteligencia artificial que se apoya en diversas arquitecturas de redes neuronales para lograr una comprensi\u00f3n y generaci\u00f3n de lenguaje humano efectiva. Aunque NLP no es una red neuronal en s\u00ed misma, su \u00e9xito se basa en la integraci\u00f3n y aplicaci\u00f3n de diferentes tipos de redes neuronales, desde Feedforward hasta Transformers, para abordar una amplia variedad de tareas ling\u00fc\u00edsticas.</p> <p>Incluir una secci\u00f3n espec\u00edfica sobre NLP en tu documento ayudar\u00e1 a clarificar c\u00f3mo este campo interact\u00faa con las distintas arquitecturas de redes neuronales, proporcionando una visi\u00f3n m\u00e1s completa de las aplicaciones y tecnolog\u00edas en inteligencia artificial.</p>"},{"location":"introduction/#9-ventajas-de-la-ia","title":"9. Ventajas de la IA","text":""},{"location":"introduction/#91-automatizacion","title":"9.1 Automatizaci\u00f3n","text":"<p>La IA puede automatizar flujos de trabajo y procesos, o bien trabajar de forma aut\u00f3noma e independiente de un equipo humano. Por ejemplo, puede ayudar a automatizar aspectos de la ciberseguridad supervisando y analizando continuamente el tr\u00e1fico de red. Del mismo modo, una f\u00e1brica inteligente puede usar al mismo tiempo decenas de tipos distintos de IA, como robots que utilizan visi\u00f3n artificial para desplazarse por la planta de producci\u00f3n o inspeccionar productos en busca de defectos, que crean gemelos digitales, o que usan anal\u00edtica en tiempo real para medir la eficiencia y los resultados.</p>"},{"location":"introduction/#92-reduce-el-error-humano","title":"9.2 Reduce el error humano","text":"<p>La IA puede eliminar los errores manuales en el procesamiento de datos, el an\u00e1lisis, el montaje en la fabricaci\u00f3n y otras tareas a trav\u00e9s de automatizaci\u00f3n y el uso de algoritmos que siguen siempre los mismos procesos.</p>"},{"location":"introduction/#93-elimina-las-tareas-repetitivas","title":"9.3 Elimina las tareas repetitivas","text":"<p>La inteligencia artificial puede usarse para llevar a cabo tareas repetitivas, lo que libera capital humano para centrarse en problemas de mayor impacto. La IA se puede utilizar para automatizar procesos, como verificar documentos, transcribir llamadas telef\u00f3nicas o responder a preguntas sencillas de los clientes, como \"\u00bfA qu\u00e9 hora cerr\u00e1is?\". Los robots suelen usarse para llevar a cabo tareas \"aburridas, sucias o peligrosas\" en lugar de una persona. </p>"},{"location":"introduction/#94-rapida-y-precisa","title":"9.4 R\u00e1pida y precisa","text":"<p>La IA puede procesar m\u00e1s informaci\u00f3n m\u00e1s r\u00e1pido que un humano, encontrar patrones y descubrir relaciones en los datos que la persona podr\u00eda pasar por alto.</p>"},{"location":"introduction/#94-disponibilidad-infinita","title":"9.4 Disponibilidad infinita","text":"<p>La IA no est\u00e1 limitada por la hora del d\u00eda, la necesidad de descansar ni otras obligaciones que tenemos las personas. Cuando se ejecutan en la nube, la IA y el aprendizaje autom\u00e1tico pueden estar \"siempre encendidos\" y trabajar continuamente en las tareas asignadas. </p>"},{"location":"introduction/#94-investigacion-y-desarrollo-agilizados","title":"9.4 Investigaci\u00f3n y desarrollo agilizados","text":"<p>La capacidad para analizar grandes cantidades de datos r\u00e1pidamente puede optimizar la investigaci\u00f3n y el desarrollo. Por ejemplo, la IA se ha utilizado para el modelado predictivo de posibles tratamientos farmac\u00e9uticos o para cuantificar el genoma humano. </p>"},{"location":"introduction/#10-aplicaciones-practicas-de-la-ia","title":"10. Aplicaciones Pr\u00e1cticas de la IA","text":"<p>La IA tiene aplicaciones pr\u00e1cticas en diversos campos, como:</p> <ul> <li>Medicina: Diagn\u00f3stico por imagen, an\u00e1lisis de datos gen\u00e9ticos, descubrimiento de f\u00e1rmacos.</li> <li>Finanzas: An\u00e1lisis de riesgos, detecci\u00f3n de fraudes, trading algor\u00edtmico.</li> <li>Automoci\u00f3n: Veh\u00edculos aut\u00f3nomos, optimizaci\u00f3n de rutas.</li> <li>Atenci\u00f3n al Cliente: Chatbots, asistentes virtuales.</li> <li>Industria del Entretenimiento: Recomendaci\u00f3n de contenido en plataformas de streaming.</li> </ul>"}]}