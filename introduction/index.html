
<!doctype html>
<html lang="es" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.34">
    
    
      
        <title>Introducción - Introducción a la Inteligencia Artificial</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.35f28582.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#introduccion-a-la-inteligencia-artificial-ia" class="md-skip">
          Saltar a contenido
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Cabecera">
    <a href=".." title="Introducción a la Inteligencia Artificial" class="md-header__button md-logo" aria-label="Introducción a la Inteligencia Artificial" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Introducción a la Inteligencia Artificial
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Introducción
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Búsqueda" placeholder="Búsqueda" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Buscar">
        
        <button type="reset" class="md-search__icon md-icon" title="Limpiar" aria-label="Limpiar" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Inicializando búsqueda
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Pestañas" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href=".." class="md-tabs__link">
          
  
  Curso IA

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../about.md" class="md-tabs__link">
        
  
    
  
  Acerca de

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navegación" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Introducción a la Inteligencia Artificial" class="md-nav__button md-logo" aria-label="Introducción a la Inteligencia Artificial" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Introducción a la Inteligencia Artificial
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Curso IA
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Curso IA
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Índice
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Introducción
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Introducción
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-que-es-la-inteligencia-artificial" class="md-nav__link">
    <span class="md-ellipsis">
      1. ¿Qué es la Inteligencia Artificial?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. ¿Qué es la Inteligencia Artificial?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-definicion" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Definición
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-como-funciona-la-ia" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 ¿Cómo funciona la IA?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-clasificacion-de-la-ia-por-capacidades" class="md-nav__link">
    <span class="md-ellipsis">
      2. Clasificación de la IA por Capacidades
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Clasificación de la IA por Capacidades">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-ia-estrecha-o-debil" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 IA Estrecha o Débil
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-ia-general-o-fuerte" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 IA General o Fuerte
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-ia-superinteligente" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 IA Superinteligente
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-clasificacion-de-la-ia-por-funcionalidad" class="md-nav__link">
    <span class="md-ellipsis">
      3. Clasificación de la IA por Funcionalidad
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Clasificación de la IA por Funcionalidad">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-ia-reactiva" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 IA Reactiva
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-ia-de-memoria-limitada" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 IA de Memoria Limitada
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-ia-con-teoria-de-la-mente" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 IA con Teoría de la Mente
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-ia-autoconsciente" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 IA Autoconsciente
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-modelos-de-entrenamiento-de-aprendizaje-automatico" class="md-nav__link">
    <span class="md-ellipsis">
      4. Modelos de entrenamiento de Aprendizaje automático
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Modelos de entrenamiento de Aprendizaje automático">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-aprendizaje-supervisado" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Aprendizaje Supervisado
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-aprendizaje-no-supervisado" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 Aprendizaje No Supervisado
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-aprendizaje-mixto-o-semisupervisado" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 Aprendizaje Mixto o Semisupervisado
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-aprendizaje-por-refuerzo" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 Aprendizaje por Refuerzo
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-deep-learning-aprendizaje-profundo" class="md-nav__link">
    <span class="md-ellipsis">
      5. Deep Learning (Aprendizaje Profundo)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tipos-de-redes-neuronales" class="md-nav__link">
    <span class="md-ellipsis">
      Tipos de Redes Neuronales
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tipos de Redes Neuronales">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-perceptron-1958" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 Perceptrón (1958)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-redes-neuronales-feedforward-redes-neuronales-de-alimentacion-directa-1960s" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 Redes Neuronales Feedforward (Redes Neuronales de Alimentación Directa) (1960s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-redes-neuronales-multicapa-multilayer-perceptron-mlp-1960s-1980s" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 Redes Neuronales Multicapa (Multilayer Perceptron, MLP) (1960s-1980s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#54-redes-neuronales-recurrentes-rnn-1980s" class="md-nav__link">
    <span class="md-ellipsis">
      5.4 Redes Neuronales Recurrentes (RNN) (1980s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#541-redes-de-hopfield-hopfield-networks-1982" class="md-nav__link">
    <span class="md-ellipsis">
      5.4.1 Redes de Hopfield (Hopfield Networks) (1982)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#542-maquinas-de-boltzmann-boltzmann-machines-1985" class="md-nav__link">
    <span class="md-ellipsis">
      5.4.2 Máquinas de Boltzmann (Boltzmann Machines) (1985)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#55-redes-neuronales-convolucionales-cnn-1980s-1990s" class="md-nav__link">
    <span class="md-ellipsis">
      5.5 Redes Neuronales Convolucionales (CNN) (1980s-1990s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#56-autoencoders-1980s-desarrollados-mas-en-2000s" class="md-nav__link">
    <span class="md-ellipsis">
      5.6 Autoencoders (1980s, desarrollados más en 2000s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#57-redes-neuronales-de-memoria-a-largo-y-corto-plazo-lstm-1997" class="md-nav__link">
    <span class="md-ellipsis">
      5.7 Redes Neuronales de Memoria a Largo y Corto Plazo (LSTM) (1997)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#58-redes-generativas-antagonicas-gan-2014" class="md-nav__link">
    <span class="md-ellipsis">
      5.8 Redes Generativas Antagónicas (GAN) (2014)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#59-arquitectura-de-transformadores-transformers-2017" class="md-nav__link">
    <span class="md-ellipsis">
      5.9 Arquitectura de Transformadores (Transformers) (2017)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#510-modelos-de-lenguaje-grandes-llm-finales-de-2018-2020s" class="md-nav__link">
    <span class="md-ellipsis">
      5.10 Modelos de Lenguaje Grandes (LLM) (Finales de 2018-2020s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#511-redes-neuronales-transformer-avanzadas-y-multimodales-2020s" class="md-nav__link">
    <span class="md-ellipsis">
      5.11 Redes Neuronales Transformer Avanzadas y Multimodales (2020s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resumen-cronologico-de-tipos-de-redes-neuronales" class="md-nav__link">
    <span class="md-ellipsis">
      Resumen Cronológico de Tipos de Redes Neuronales
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#-" class="md-nav__link">
    <span class="md-ellipsis">
      ---
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-modelos-de-lenguaje-de-gran-tamano-llm" class="md-nav__link">
    <span class="md-ellipsis">
      6. Modelos de Lenguaje de Gran Tamaño (LLM)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Modelos de Lenguaje de Gran Tamaño (LLM)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#que-son-los-llm" class="md-nav__link">
    <span class="md-ellipsis">
      ¿Qué son los LLM?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#61-proceso-de-entrenamiento" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 Proceso de Entrenamiento
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-relacion-entre-llm-y-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 Relación entre LLM y Transformers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-aplicaciones-de-los-llm" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 Aplicaciones de los LLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-desafios-y-consideraciones-eticas" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 Desafíos y Consideraciones Éticas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64-avances-y-tendencias-recientes" class="md-nav__link">
    <span class="md-ellipsis">
      6.4 Avances y Tendencias Recientes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65-impacto-en-la-sociedad-y-el-futuro" class="md-nav__link">
    <span class="md-ellipsis">
      6.5 Impacto en la Sociedad y el Futuro
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#66-ejemplos-de-llm" class="md-nav__link">
    <span class="md-ellipsis">
      6.6 Ejemplos de LLM:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7. Redes Neuronales Multimodales
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Redes Neuronales Multimodales">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-que-son-las-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 ¿Qué son las Redes Neuronales Multimodales?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-caracteristicas-principales" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 Características Principales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-arquitectura-y-funcionamiento" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 Arquitectura y Funcionamiento
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.3 Arquitectura y Funcionamiento">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#731-componentes-de-las-redes-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.1 Componentes de las Redes Multimodales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#732-mecanismos-de-atencion-multimodal" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.2 Mecanismos de Atención Multimodal
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-aplicaciones-de-las-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 Aplicaciones de las Redes Neuronales Multimodales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75-ejemplos-notables-de-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.5 Ejemplos Notables de Redes Neuronales Multimodales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#76-ventajas-de-las-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.6 Ventajas de las Redes Neuronales Multimodales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#77-desafios-de-las-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.7 Desafíos de las Redes Neuronales Multimodales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#78-conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      7.8 Conclusión
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-procesamiento-de-lenguaje-natural-nlp-y-redes-neuronales" class="md-nav__link">
    <span class="md-ellipsis">
      8. Procesamiento de Lenguaje Natural (NLP) y Redes Neuronales
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Procesamiento de Lenguaje Natural (NLP) y Redes Neuronales">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#redes-neuronales-feedforward-ff-en-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Redes Neuronales Feedforward (FF) en NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#redes-neuronales-recurrentes-rnn-y-lstm-en-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Redes Neuronales Recurrentes (RNN) y LSTM en NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#arquitectura-de-transformadores-en-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Arquitectura de Transformadores en NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#redes-generativas-antagonicas-gan-en-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Redes Generativas Antagónicas (GAN) en NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusión
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-ventajas-de-la-ia" class="md-nav__link">
    <span class="md-ellipsis">
      9. Ventajas de la IA
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Ventajas de la IA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-automatizacion" class="md-nav__link">
    <span class="md-ellipsis">
      9.1 Automatización
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-reduce-el-error-humano" class="md-nav__link">
    <span class="md-ellipsis">
      9.2 Reduce el error humano
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-elimina-las-tareas-repetitivas" class="md-nav__link">
    <span class="md-ellipsis">
      9.3 Elimina las tareas repetitivas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-rapida-y-precisa" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 Rápida y precisa
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-disponibilidad-infinita" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 Disponibilidad infinita
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-investigacion-y-desarrollo-agilizados" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 Investigación y desarrollo agilizados
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-aplicaciones-practicas-de-la-ia" class="md-nav__link">
    <span class="md-ellipsis">
      10. Aplicaciones Prácticas de la IA
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../about.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Acerca de
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Tabla de contenidos">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Tabla de contenidos
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-que-es-la-inteligencia-artificial" class="md-nav__link">
    <span class="md-ellipsis">
      1. ¿Qué es la Inteligencia Artificial?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. ¿Qué es la Inteligencia Artificial?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-definicion" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Definición
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-como-funciona-la-ia" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 ¿Cómo funciona la IA?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-clasificacion-de-la-ia-por-capacidades" class="md-nav__link">
    <span class="md-ellipsis">
      2. Clasificación de la IA por Capacidades
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Clasificación de la IA por Capacidades">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-ia-estrecha-o-debil" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 IA Estrecha o Débil
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-ia-general-o-fuerte" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 IA General o Fuerte
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-ia-superinteligente" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 IA Superinteligente
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-clasificacion-de-la-ia-por-funcionalidad" class="md-nav__link">
    <span class="md-ellipsis">
      3. Clasificación de la IA por Funcionalidad
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Clasificación de la IA por Funcionalidad">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-ia-reactiva" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 IA Reactiva
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-ia-de-memoria-limitada" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 IA de Memoria Limitada
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-ia-con-teoria-de-la-mente" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 IA con Teoría de la Mente
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-ia-autoconsciente" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 IA Autoconsciente
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-modelos-de-entrenamiento-de-aprendizaje-automatico" class="md-nav__link">
    <span class="md-ellipsis">
      4. Modelos de entrenamiento de Aprendizaje automático
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Modelos de entrenamiento de Aprendizaje automático">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-aprendizaje-supervisado" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Aprendizaje Supervisado
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-aprendizaje-no-supervisado" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 Aprendizaje No Supervisado
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-aprendizaje-mixto-o-semisupervisado" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 Aprendizaje Mixto o Semisupervisado
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-aprendizaje-por-refuerzo" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 Aprendizaje por Refuerzo
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-deep-learning-aprendizaje-profundo" class="md-nav__link">
    <span class="md-ellipsis">
      5. Deep Learning (Aprendizaje Profundo)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tipos-de-redes-neuronales" class="md-nav__link">
    <span class="md-ellipsis">
      Tipos de Redes Neuronales
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tipos de Redes Neuronales">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-perceptron-1958" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 Perceptrón (1958)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-redes-neuronales-feedforward-redes-neuronales-de-alimentacion-directa-1960s" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 Redes Neuronales Feedforward (Redes Neuronales de Alimentación Directa) (1960s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-redes-neuronales-multicapa-multilayer-perceptron-mlp-1960s-1980s" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 Redes Neuronales Multicapa (Multilayer Perceptron, MLP) (1960s-1980s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#54-redes-neuronales-recurrentes-rnn-1980s" class="md-nav__link">
    <span class="md-ellipsis">
      5.4 Redes Neuronales Recurrentes (RNN) (1980s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#541-redes-de-hopfield-hopfield-networks-1982" class="md-nav__link">
    <span class="md-ellipsis">
      5.4.1 Redes de Hopfield (Hopfield Networks) (1982)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#542-maquinas-de-boltzmann-boltzmann-machines-1985" class="md-nav__link">
    <span class="md-ellipsis">
      5.4.2 Máquinas de Boltzmann (Boltzmann Machines) (1985)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#55-redes-neuronales-convolucionales-cnn-1980s-1990s" class="md-nav__link">
    <span class="md-ellipsis">
      5.5 Redes Neuronales Convolucionales (CNN) (1980s-1990s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#56-autoencoders-1980s-desarrollados-mas-en-2000s" class="md-nav__link">
    <span class="md-ellipsis">
      5.6 Autoencoders (1980s, desarrollados más en 2000s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#57-redes-neuronales-de-memoria-a-largo-y-corto-plazo-lstm-1997" class="md-nav__link">
    <span class="md-ellipsis">
      5.7 Redes Neuronales de Memoria a Largo y Corto Plazo (LSTM) (1997)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#58-redes-generativas-antagonicas-gan-2014" class="md-nav__link">
    <span class="md-ellipsis">
      5.8 Redes Generativas Antagónicas (GAN) (2014)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#59-arquitectura-de-transformadores-transformers-2017" class="md-nav__link">
    <span class="md-ellipsis">
      5.9 Arquitectura de Transformadores (Transformers) (2017)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#510-modelos-de-lenguaje-grandes-llm-finales-de-2018-2020s" class="md-nav__link">
    <span class="md-ellipsis">
      5.10 Modelos de Lenguaje Grandes (LLM) (Finales de 2018-2020s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#511-redes-neuronales-transformer-avanzadas-y-multimodales-2020s" class="md-nav__link">
    <span class="md-ellipsis">
      5.11 Redes Neuronales Transformer Avanzadas y Multimodales (2020s)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#resumen-cronologico-de-tipos-de-redes-neuronales" class="md-nav__link">
    <span class="md-ellipsis">
      Resumen Cronológico de Tipos de Redes Neuronales
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#-" class="md-nav__link">
    <span class="md-ellipsis">
      ---
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-modelos-de-lenguaje-de-gran-tamano-llm" class="md-nav__link">
    <span class="md-ellipsis">
      6. Modelos de Lenguaje de Gran Tamaño (LLM)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Modelos de Lenguaje de Gran Tamaño (LLM)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#que-son-los-llm" class="md-nav__link">
    <span class="md-ellipsis">
      ¿Qué son los LLM?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#61-proceso-de-entrenamiento" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 Proceso de Entrenamiento
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#62-relacion-entre-llm-y-transformers" class="md-nav__link">
    <span class="md-ellipsis">
      6.2 Relación entre LLM y Transformers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-aplicaciones-de-los-llm" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 Aplicaciones de los LLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#63-desafios-y-consideraciones-eticas" class="md-nav__link">
    <span class="md-ellipsis">
      6.3 Desafíos y Consideraciones Éticas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#64-avances-y-tendencias-recientes" class="md-nav__link">
    <span class="md-ellipsis">
      6.4 Avances y Tendencias Recientes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#65-impacto-en-la-sociedad-y-el-futuro" class="md-nav__link">
    <span class="md-ellipsis">
      6.5 Impacto en la Sociedad y el Futuro
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#66-ejemplos-de-llm" class="md-nav__link">
    <span class="md-ellipsis">
      6.6 Ejemplos de LLM:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7. Redes Neuronales Multimodales
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Redes Neuronales Multimodales">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-que-son-las-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 ¿Qué son las Redes Neuronales Multimodales?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-caracteristicas-principales" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 Características Principales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-arquitectura-y-funcionamiento" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 Arquitectura y Funcionamiento
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7.3 Arquitectura y Funcionamiento">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#731-componentes-de-las-redes-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.1 Componentes de las Redes Multimodales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#732-mecanismos-de-atencion-multimodal" class="md-nav__link">
    <span class="md-ellipsis">
      7.3.2 Mecanismos de Atención Multimodal
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-aplicaciones-de-las-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 Aplicaciones de las Redes Neuronales Multimodales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#75-ejemplos-notables-de-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.5 Ejemplos Notables de Redes Neuronales Multimodales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#76-ventajas-de-las-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.6 Ventajas de las Redes Neuronales Multimodales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#77-desafios-de-las-redes-neuronales-multimodales" class="md-nav__link">
    <span class="md-ellipsis">
      7.7 Desafíos de las Redes Neuronales Multimodales
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#78-conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      7.8 Conclusión
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-procesamiento-de-lenguaje-natural-nlp-y-redes-neuronales" class="md-nav__link">
    <span class="md-ellipsis">
      8. Procesamiento de Lenguaje Natural (NLP) y Redes Neuronales
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Procesamiento de Lenguaje Natural (NLP) y Redes Neuronales">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#redes-neuronales-feedforward-ff-en-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Redes Neuronales Feedforward (FF) en NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#redes-neuronales-recurrentes-rnn-y-lstm-en-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Redes Neuronales Recurrentes (RNN) y LSTM en NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#arquitectura-de-transformadores-en-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Arquitectura de Transformadores en NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#redes-generativas-antagonicas-gan-en-nlp" class="md-nav__link">
    <span class="md-ellipsis">
      Redes Generativas Antagónicas (GAN) en NLP
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusión
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-ventajas-de-la-ia" class="md-nav__link">
    <span class="md-ellipsis">
      9. Ventajas de la IA
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Ventajas de la IA">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-automatizacion" class="md-nav__link">
    <span class="md-ellipsis">
      9.1 Automatización
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-reduce-el-error-humano" class="md-nav__link">
    <span class="md-ellipsis">
      9.2 Reduce el error humano
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-elimina-las-tareas-repetitivas" class="md-nav__link">
    <span class="md-ellipsis">
      9.3 Elimina las tareas repetitivas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-rapida-y-precisa" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 Rápida y precisa
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-disponibilidad-infinita" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 Disponibilidad infinita
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#94-investigacion-y-desarrollo-agilizados" class="md-nav__link">
    <span class="md-ellipsis">
      9.4 Investigación y desarrollo agilizados
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-aplicaciones-practicas-de-la-ia" class="md-nav__link">
    <span class="md-ellipsis">
      10. Aplicaciones Prácticas de la IA
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="introduccion-a-la-inteligencia-artificial-ia"><strong>Introducción a la Inteligencia Artificial (IA)</strong></h1>
<h2 id="1-que-es-la-inteligencia-artificial"><strong>1. ¿Qué es la Inteligencia Artificial?</strong></h2>
<h3 id="11-definicion"><strong>1.1 Definición</strong></h3>
<p>La <strong>inteligencia artificial (IA)</strong> La inteligencia artificial es un campo de la ciencia relacionado con la creación de ordenadores y máquinas que pueden razonar, aprender y actuar de una forma que normalmente necesitaría inteligencia humana o que consuma datos cuya escala supere lo que las personas pueden analizar. </p>
<p>La IA es un campo amplio que abarca muchas disciplinas diferentes, como la informática, estadística y analítica de datos, ingeniería de hardware y software, lingüística, neurociencia e incluso filosofía y psicología. </p>
<p>A nivel operativo para el uso empresarial, la IA es un conjunto de tecnologías basadas principalmente en aprendizaje automático y aprendizaje profundo, que se usan para analíticas de datos, predicciones y previsiones, categorización de objetos, procesamiento del lenguaje natural, recomendaciones, recuperación inteligente de datos y mucho más.
Es por tanto, simulación de procesos humanos por parte de máquinas, especialmente sistemas informáticos. Estos procesos incluyen el aprendizaje (adquirir información y reglas para usarla), el razonamiento (usar reglas para llegar a conclusiones aproximadas o definidas) y la autocorrección. Existen diferentes niveles y tipos de IA según su capacidad y funcionalidad.</p>
<h3 id="12-como-funciona-la-ia"><strong>1.2 ¿Cómo funciona la IA?</strong></h3>
<p>Aunque los detalles varían según las técnicas de IA, el principio fundamental gira en torno a los datos. Los sistemas de IA aprenden y mejoran a través de la exposición a grandes cantidades de datos, identificando patrones y relaciones que los humanos pueden pasar por alto.</p>
<p>Este proceso de aprendizaje a menudo implica algoritmos, que son conjuntos de reglas o instrucciones que guían el análisis y la toma de decisiones de la IA. En el aprendizaje automático, un subconjunto popular de IA, los algoritmos se entrenan con datos etiquetados o sin etiquetar para hacer predicciones o categorizar información. </p>
<p>El aprendizaje profundo, otra especialización, utiliza redes neuronales artificiales con varias capas para procesar la información, imitando la estructura y la función del cerebro humano. Gracias al aprendizaje y la adaptación continuos, los sistemas de IA son cada vez más expertos en realizar tareas específicas, desde reconocer imágenes hasta traducir idiomas, etc.</p>
<hr />
<h2 id="2-clasificacion-de-la-ia-por-capacidades"><strong>2. Clasificación de la IA por Capacidades</strong></h2>
<h3 id="21-ia-estrecha-o-debil"><strong>2.1 IA Estrecha o Débil</strong></h3>
<p>La <strong>IA Estrecha</strong> (también llamada IA débil) se refiere a sistemas diseñados para realizar una tarea específica. Estos sistemas no tienen consciencia, conocimiento general ni capacidades más allá de su tarea específica. Se considera inteligencia limitada porque solo puede llevar a cabo conjuntos de acciones delimitados por su programación y entrenamiento 
Ejemplos incluyen:
- Asistentes virtuales (Siri, Alexa)
- Motores de búsqueda
- Sistemas de recomendación</p>
<!-- ![Ejemplo de IA Estrecha](./images/IA_Estrecha.webp){width=400px} -->

<h3 id="22-ia-general-o-fuerte"><strong>2.2 IA General o Fuerte</strong></h3>
<p>La <strong>IA General</strong> es teórica por ahora y se refiere a una IA que puede realizar cualquier tarea cognitiva que un ser humano puede realizar. Una IA General puede aprender de sus experiencias y aplicar ese conocimiento en nuevas situaciones.
Sería la capacidad de una máquina para "sentir, pensar y actuar" como lo haría una persona. Actualmente, la AGI no existe</p>
<!-- ![Ejemplo de IA General](./images/IA_General.webp){width=400px} -->

<h3 id="23-ia-superinteligente"><strong>2.3 IA Superinteligente</strong></h3>
<p>La <strong>IA Superinteligente</strong> va más allá de la inteligencia humana en todos los aspectos. Sería capaz de resolver problemas mucho más complejos de lo que los humanos pueden, tomando decisiones con una capacidad y velocidad incomparables. Esta IA aún es hipotética.</p>
<!-- ![Ejemplo de IA Superinteligente](./images/IA_Superinteligente.webp){width=400px} -->

<hr />
<h2 id="3-clasificacion-de-la-ia-por-funcionalidad"><strong>3. Clasificación de la IA por Funcionalidad</strong></h2>
<h3 id="31-ia-reactiva"><strong>3.1 IA Reactiva</strong></h3>
<p>La <strong>IA Reactiva</strong> es la más básica de todas. No tiene memoria y solo responde a estímulos en tiempo real que ya tiene preprogramadas. Un buen ejemplo de IA reactiva es <strong>Deep Blue</strong>, el sistema de ajedrez de IBM que venció a Garry Kasparov. No utiliza memoria y, por lo tanto, no puede aprender con datos nuevos. Solo analiza las jugadas actuales sin considerar experiencias previas.</p>
<!-- ![Ejemplo de IA Reactiva](./images/IA_Reactiva.webp){width=400px} -->

<h3 id="32-ia-de-memoria-limitada"><strong>3.2 IA de Memoria Limitada</strong></h3>
<p>La <strong>IA de Memoria Limitada</strong> es un paso adelante, ya que puede almacenar datos temporales para tomar decisiones basadas en experiencias recientes. 
La <strong>IA más moderna</strong> se considera una memoria limitada. Puede usarla para mejorar con el tiempo entrenándose con nuevos datos, normalmente a través de una red neuronal artificial u otro modelo de entrenamiento. El <strong>aprendizaje profundo</strong>, un subconjunto del aprendizaje automático, se considera inteligencia artificial de memoria limitada.
Ejemplos comunes incluyen:
- <strong>Vehículos autónomos</strong>: Los coches inteligentes pueden recordar la ubicación de otros vehículos, señales de tráfico y la velocidad para tomar decisiones más informadas.</p>
<!-- ![Ejemplo de IA de Memoria Limitada](./images/IA_Memoria_Limitada.webp){width=400px} -->

<h3 id="33-ia-con-teoria-de-la-mente"><strong>3.3 IA con Teoría de la Mente</strong></h3>
<p>Este tipo de IA es capaz de entender las emociones, creencias e intenciones de otros seres. Aunque todavía no se ha desarrollado completamente, es un área activa de investigación. Se espera que permita interacciones más avanzadas entre humanos y máquinas. Es una IA que puede emular la mente humana y que tiene funciones de toma de decisiones similares a las de una persona.</p>
<!-- ![Ejemplo de IA con Teoría de la Mente](./images/IA_Teoria_de_la_Mente.webp){width=400px} -->

<h3 id="34-ia-autoconsciente"><strong>3.4 IA Autoconsciente</strong></h3>
<p>La <strong>IA Autoconsciente</strong> es una IA avanzada que tendría una forma de consciencia similar a la humana. Sería capaz de entender su propia existencia, tener emociones y posiblemente incluso desarrollar una ética.  Al igual que la IA de teoría de la mente, la consciente de sí misma no existe actualmente.</p>
<!-- ![Ejemplo de IA Autoconsciente](./images/IA_Autoconsciente.webp){width=400px} -->

<hr />
<h2 id="4-modelos-de-entrenamiento-de-aprendizaje-automatico"><strong>4. Modelos de entrenamiento de Aprendizaje automático</strong></h2>
<p>Cuando las empresas hablan de IA, a menudo hablan de "datos de entrenamiento". Pero ¿qué significa esto? Recuerda que la inteligencia artificial con memoria limitada es la IA que mejora con el tiempo al entrenarse con datos nuevos</p>
<p><strong>El aprendizaje automático (Machine Learning)</strong> es un subconjunto de la IA que permite que las máquinas aprendan de los datos sin ser explícitamente programadas. Utiliza algoritmos para encontrar patrones en los datos y predecir resultados.</p>
<h3 id="41-aprendizaje-supervisado"><strong>4.1 Aprendizaje Supervisado</strong></h3>
<p>El <strong>aprendizaje supervisado</strong>  es un modelo de aprendizaje automático que asigna una entrada específica a un resultado usando datos de entrenamiento etiquetados, después el sistema debe aprender a predecir una salida a partir de una entrada específica. Ejemplos incluyen:
- Clasificación de imágenes (gatos vs perros)
- Reconocimiento de voz
- Diagnósticos médicos</p>
<h3 id="42-aprendizaje-no-supervisado"><strong>4.2 Aprendizaje No Supervisado</strong></h3>
<p>En el <strong>aprendizaje no supervisado</strong>, el sistema recibe datos sin etiquetas y debe identificar patrones por sí mismo.  A diferencia del aprendizaje supervisado, el resultado final no se sabe con antelación. En vez de eso, el algoritmo aprende de los datos y los clasifica en grupos según sus atributos. Por ejemplo, el aprendizaje no supervisado es bueno para identificar patrones coincidentes y definir modelos descriptivos. Se usa comúnmente en:
- Agrupamiento (clustering) de datos
- Reducción de dimensionalidad
- Análisis de segmentación de mercado</p>
<h3 id="43-aprendizaje-mixto-o-semisupervisado"><strong>4.3 Aprendizaje Mixto o Semisupervisado</strong></h3>
<p>Además del aprendizaje supervisado y no supervisado, se suele emplear un enfoque mixto, llamado aprendizaje semisupervisado, en el que solo se etiquetan algunos datos. Aunque el resultado final del aprendizaje semisupervisado ya se conoce, el algoritmo tiene que saber cómo organizar y estructurar los datos para lograr los resultados deseados.
- LLM (Large Language Model)</p>
<h3 id="44-aprendizaje-por-refuerzo"><strong>4.4 Aprendizaje por Refuerzo</strong></h3>
<p>El <strong>aprendizaje por refuerzo</strong> entrena a un agente para tomar decisiones en un entorno, maximizando recompensas a lo largo del tiempo. Es decir, es un modelo de aprendizaje automático que se puede describir, en líneas generales, como "aprender con la práctica". Un "agente" aprende a llevar a cabo una tarea definida mediante ensayo y error (un bucle de retroalimentación) hasta que su rendimiento se encuentra dentro del intervalo deseado. El agente recibe refuerzo positivo cuando hace la tarea bien y refuerzo negativo cuando falla.
Se utiliza mucho en robótica, juegos y control autónomo. Ejemplos incluyen:
- Drones
- Juegos como <strong>AlphaGo</strong> de Google DeepMind</p>
<hr />
<h2 id="5-deep-learning-aprendizaje-profundo"><strong>5. Deep Learning (Aprendizaje Profundo)</strong></h2>
<p>El <strong>Deep Learning</strong> es un subconjunto del aprendizaje automático que utiliza redes neuronales profundas para identificar patrones en grandes cantidades de datos. </p>
<p>Una red neuronal es un sistema de neuronas artificiales, a veces llamadas "perceptrones", que son nodos computacionales que se usan para clasificar y analizar datos. Los datos se ingieren en la primera capa de una red neuronal, cada uno de los perceptrones toma una decisión y, a continuación, transmite esa información a varios nodos en la siguiente capa. Los modelos de entrenamiento con más de tres capas se denominan "redes neuronales profundas" o "aprendizaje profundo". Algunas redes neuronales modernas tienen cientos o miles de capas. El resultado de los perceptrones finales es llevar a cabo la tarea definida en la red neuronal, como clasificar un objeto o encontrar patrones en los datos. </p>
<p>Aquí están los principales tipos de redes neuronales utilizadas en Deep Learning:</p>
<h2 id="tipos-de-redes-neuronales"><strong>Tipos de Redes Neuronales</strong></h2>
<h3 id="51-perceptron-1958"><strong>5.1 Perceptrón (1958)</strong></h3>
<ul>
<li><strong>Año de Aparición:</strong> 1958</li>
<li><strong>Descripción:</strong> Introducido por <strong>Frank Rosenblatt</strong>, el perceptrón es la forma más básica de red neuronal. Consiste en una única capa de nodos (neuronas) que realiza clasificaciones binarias. Aunque es limitado en su capacidad (no puede resolver problemas no lineales como el XOR), sentó las bases para el desarrollo de redes neuronales más complejas.</li>
</ul>
<h3 id="52-redes-neuronales-feedforward-redes-neuronales-de-alimentacion-directa-1960s"><strong>5.2 Redes Neuronales Feedforward (Redes Neuronales de Alimentación Directa) (1960s)</strong></h3>
<ul>
<li><strong>Año de Aparición:</strong> 1960s</li>
<li><strong>Descripción:</strong> Las Redes Neuronales Feedforward (FF) son el tipo más básico de redes neuronales artificiales. En estas redes, la información fluye en una sola dirección, desde las capas de entrada hasta las capas de salida, sin ciclos ni conexiones recurrentes. Son ideales para tareas de clasificación y regresión. Las redes neuronales de retroalimentación suelen estar emparejadas con un algoritmo de corrección de errores llamado "backpropagation" que, a grandes rasgos, empieza por el resultado de la red neuronal y vuelve hasta el principio mientras detecta errores para mejorar la precisión de la red neuronal. Muchas redes neuronales sencillas pero potentes son de retroalimentación profunda.</li>
</ul>
<h3 id="53-redes-neuronales-multicapa-multilayer-perceptron-mlp-1960s-1980s"><strong>5.3 Redes Neuronales Multicapa (Multilayer Perceptron, MLP) (1960s-1980s)</strong></h3>
<ul>
<li><strong>Año de Aparición:</strong> 1960s (concepto), popularizadas en 1980s</li>
<li><strong>Descripción:</strong> Las MLP consisten en múltiples capas de neuronas (entrada, ocultas y salida) y utilizan algoritmos de retropropagación para el entrenamiento. Pueden resolver problemas no lineales y son la base de muchas arquitecturas modernas.</li>
</ul>
<h3 id="54-redes-neuronales-recurrentes-rnn-1980s"><strong>5.4 Redes Neuronales Recurrentes (RNN) (1980s)</strong></h3>
<ul>
<li><strong>Año de Aparición:</strong> 1980s</li>
<li>
<p><strong>Descripción:</strong> Las RNN tienen conexiones recurrentes que permiten mantener una memoria interna de secuencias anteriores, lo que las hace ideales para tareas de procesamiento de secuencias como el reconocimiento de voz y el análisis de texto.</p>
</li>
<li>
<h3 id="541-redes-de-hopfield-hopfield-networks-1982"><strong>5.4.1 Redes de Hopfield (Hopfield Networks) (1982)</strong></h3>
</li>
<li>
<p><strong>Año de Aparición:</strong> 1982</p>
</li>
<li>
<p><strong>Descripción:</strong> Introducidas por <strong>John Hopfield</strong>, estas redes son redes completamente conectadas y recurrentes utilizadas para la memoria asociativa y la optimización de problemas combinatorios.</p>
</li>
<li>
<h3 id="542-maquinas-de-boltzmann-boltzmann-machines-1985"><strong>5.4.2 Máquinas de Boltzmann (Boltzmann Machines) (1985)</strong></h3>
</li>
<li>
<p><strong>Año de Aparición:</strong> 1985</p>
</li>
<li><strong>Descripción:</strong> Propuestas por <strong>Geoffrey Hinton</strong> y <strong>Terry Sejnowski</strong>, las Máquinas de Boltzmann son redes estocásticas y recurrentes que pueden aprender distribuciones de probabilidad sobre sus entradas, utilizadas principalmente para el aprendizaje no supervisado.</li>
</ul>
<h3 id="55-redes-neuronales-convolucionales-cnn-1980s-1990s"><strong>5.5 Redes Neuronales Convolucionales (CNN) (1980s-1990s)</strong></h3>
<ul>
<li><strong>Año de Aparición:</strong> 1980s (concepto), popularizadas en 1998 con <strong>LeNet</strong></li>
<li><strong>Descripción:</strong> Introducidas por <strong>Yann LeCun</strong> con la arquitectura <strong>LeNet</strong> para reconocimiento de dígitos escritos a mano. Las CNNs suelen usarse en el reconocimiento de imágenes y utilizan varias capas separadas (una capa convolucional y luego una capa de agrupación) que filtran las diferentes partes de una imagen antes de volver a juntarlas (en la capa completamente conectada). Las primeras capas convolucionales pueden buscar elementos simples de una imagen, como colores y bordes, antes de buscar características más complejas en capas adicionales.</li>
</ul>
<h3 id="56-autoencoders-1980s-desarrollados-mas-en-2000s"><strong>5.6 Autoencoders (1980s, desarrollados más en 2000s)</strong></h3>
<ul>
<li><strong>Año de Aparición:</strong> 1980s (concepto), avances significativos en 2000s</li>
<li><strong>Descripción:</strong> Los autoencoders son redes neuronales diseñadas para aprender representaciones compactas (codificaciones) de los datos de entrada, útiles para reducción de dimensionalidad, generación de datos y preentrenamiento de redes profundas.</li>
</ul>
<h3 id="57-redes-neuronales-de-memoria-a-largo-y-corto-plazo-lstm-1997"><strong>5.7 Redes Neuronales de Memoria a Largo y Corto Plazo (LSTM) (1997)</strong></h3>
<ul>
<li><strong>Año de Aparición:</strong> 1997</li>
<li><strong>Descripción:</strong> Introducidas por <strong>Sepp Hochreiter</strong> y <strong>Jürgen Schmidhuber</strong>, son una forma avanzada de RNN que pueden usar la memoria para "recordar" lo que ha ocurrido en capas anteriores. La única diferencia entre las RNNs y las LSTMs es que estas últimas pueden recordar lo que ocurrió hace varias capas gracias al uso de celdas de memoria. Las LSTMs se suelen usar en el reconocimiento de voz y para hacer predicciones. </li>
</ul>
<h3 id="58-redes-generativas-antagonicas-gan-2014"><strong>5.8 Redes Generativas Antagónicas (GAN) (2014)</strong></h3>
<ul>
<li><strong>Año de Aparición:</strong> 2014</li>
<li><strong>Descripción:</strong> Propuestas por <strong>Ian Goodfellow</strong> y sus colegas, las GAN consisten en dos redes  que compiten entre sí para generar datos sintéticos realistas. Una red (la generadora) crea ejemplos que la otra red (la discriminadora) intenta demostrar si son verdaderos o falsos.  Han revolucionado la generación de imágenes, síntesis de voz y creación de contenido multimedia.</li>
</ul>
<h3 id="59-arquitectura-de-transformadores-transformers-2017"><strong>5.9 Arquitectura de Transformadores (Transformers) (2017)</strong></h3>
<ul>
<li><strong>Año de Aparición:</strong> 2017</li>
<li><strong>Descripción:</strong> Introducida en el artículo <strong>"Attention is All You Need"</strong> por <strong>Vaswani et al.</strong>, la arquitectura de transformadores utiliza mecanismos de atención para procesar datos en paralelo, superando a las RNN y CNN en tareas de procesamiento de lenguaje natural (NLP) y permitiendo la creación de modelos más escalables.</li>
</ul>
<h3 id="510-modelos-de-lenguaje-grandes-llm-finales-de-2018-2020s"><strong>5.10 Modelos de Lenguaje Grandes (LLM) (Finales de 2018-2020s)</strong></h3>
<ul>
<li><strong>Año de Aparición:</strong> Finales de 2010s</li>
<li><strong>Descripción:</strong> Basados en la arquitectura de transformadores, los LLM como <strong>GPT (Generative Pre-trained Transformer)</strong>, <strong>BERT (Bidirectional Encoder Representations from Transformers)</strong> y <strong>T5 (Text-To-Text Transfer Transformer)</strong> han alcanzado niveles avanzados en comprensión y generación de lenguaje natural, siendo utilizados en una amplia variedad de aplicaciones como chatbots, traducción automática y análisis de sentimientos.</li>
</ul>
<h3 id="511-redes-neuronales-transformer-avanzadas-y-multimodales-2020s"><strong>5.11 Redes Neuronales Transformer Avanzadas y Multimodales (2020s)</strong></h3>
<ul>
<li><strong>Año de Aparición:</strong> 2020s</li>
<li><strong>Descripción:</strong> Evoluciones de la arquitectura de transformadores que integran múltiples modalidades de datos (texto, imágenes, audio). Ejemplos incluyen <strong>CLIP</strong> de OpenAI, que combina procesamiento de imágenes con lenguaje, y modelos como <strong>DALL·E</strong> que generan imágenes a partir de descripciones textuales.</li>
</ul>
<hr />
<h3 id="resumen-cronologico-de-tipos-de-redes-neuronales"><strong>Resumen Cronológico de Tipos de Redes Neuronales</strong></h3>
<table>
<thead>
<tr>
<th>Año</th>
<th>Tipo de Red Neuronal</th>
<th>Descripción Breve</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>1958</strong></td>
<td>Perceptrón</td>
<td>Red neuronal básica para clasificación binaria.</td>
</tr>
<tr>
<td><strong>1960s</strong></td>
<td>Redes Neuronales Feedforward (FF)</td>
<td>Redes con flujo de información en una sola dirección, sin retroalimentación.</td>
</tr>
<tr>
<td><strong>1960s-1980s</strong></td>
<td>Redes Neuronales Multicapa (MLP)</td>
<td>Redes con múltiples capas y retropropagación para problemas no lineales.</td>
</tr>
<tr>
<td><strong>1980s</strong></td>
<td>Redes Neuronales Recurrentes (RNN)</td>
<td>Redes para procesamiento de secuencias con memoria interna.</td>
</tr>
<tr>
<td><strong>1982</strong></td>
<td>Redes de Hopfield</td>
<td>Redes totalmente conectadas para memoria asociativa y optimización.</td>
</tr>
<tr>
<td><strong>1985</strong></td>
<td>Máquinas de Boltzmann</td>
<td>Redes estocásticas para aprendizaje no supervisado.</td>
</tr>
<tr>
<td><strong>1980s-1990s</strong></td>
<td>Redes Neuronales Convolucionales (CNN)</td>
<td>Redes para extracción de características espaciales en imágenes.</td>
</tr>
<tr>
<td><strong>1980s-2000s</strong></td>
<td>Autoencoders</td>
<td>Redes para aprendizaje de representaciones compactas de datos.</td>
</tr>
<tr>
<td><strong>1997</strong></td>
<td>LSTM</td>
<td>RNN avanzadas para manejar dependencias a largo plazo.</td>
</tr>
<tr>
<td><strong>2014</strong></td>
<td>Redes Generativas Antagónicas (GAN)</td>
<td>Redes para generación de datos sintéticos realistas.</td>
</tr>
<tr>
<td><strong>2017</strong></td>
<td>Arquitectura de Transformadores (Transformers)</td>
<td>Redes basadas en mecanismos de atención para procesamiento paralelo.</td>
</tr>
<tr>
<td><strong>2018-2020s</strong></td>
<td>Modelos de Lenguaje Grandes (LLM)</td>
<td>Modelos basados en transformadores para comprensión y generación de lenguaje.</td>
</tr>
<tr>
<td><strong>2020s</strong></td>
<td>Redes Neuronales Transformer Avanzadas y Multimodales</td>
<td>Modelos que integran múltiples tipos de datos (texto, imágenes, audio).</td>
</tr>
</tbody>
</table>
<h2 id="-">---</h2>
<h2 id="6-modelos-de-lenguaje-de-gran-tamano-llm">6. Modelos de Lenguaje de Gran Tamaño (LLM)</h2>
<p>Los <strong>Modelos de Lenguaje de Gran Tamaño (LLM, por sus siglas en inglés)</strong> han transformado el campo del procesamiento del lenguaje natural (NLP) al permitir que las máquinas comprendan y generen texto humano de manera coherente y contextual. A continuación, exploramos su origen, las arquitecturas que los sustentan, los principales modelos, su proceso de entrenamiento, aplicaciones y consideraciones éticas.</p>
<h3 id="que-son-los-llm"><strong>¿Qué son los LLM?</strong></h3>
<p>Los LLM son modelos de inteligencia artificial que utilizan <strong>redes neuronales profundas</strong> para procesar y generar lenguaje humano. Están entrenados en <strong>enormes conjuntos de datos textuales</strong>, lo que les permite aprender patrones lingüísticos, semántica y sintaxis del lenguaje natural. Basados en la arquitectura de Transformadores.</p>
<h3 id="61-proceso-de-entrenamiento"><strong>6.1 Proceso de Entrenamiento</strong></h3>
<ul>
<li><strong>Datos Masivos:</strong> Se entrenan con terabytes de texto que incluyen libros, artículos, sitios web y otros recursos.</li>
<li><strong>Aprendizaje mixto:</strong> Aprenden de manera autónoma sin necesidad de etiquetado manual, mediante tareas como la predicción de la siguiente palabra en una oración.</li>
<li><strong>Contexto y Coherencia:</strong> Gracias a su arquitectura, pueden mantener el contexto a lo largo de largas secuencias de texto, mejorando la coherencia en las respuestas.</li>
<li><strong>Fine-Tuning (Ajuste Fino):</strong> Después del preentrenamiento, los modelos pueden ajustarse para tareas específicas utilizando conjuntos de datos más pequeños y especializados.</li>
</ul>
<h3 id="62-relacion-entre-llm-y-transformers"><strong>6.2 Relación entre LLM y Transformers</strong></h3>
<p>Los Transformers han demostrado ser altamente efectivos para tareas de NLP, y la mayoría de los LLM modernos se basan en esta arquitectura. </p>
<ul>
<li><strong>Eficiencia Computacional:</strong> Permiten entrenamiento en paralelo.</li>
<li><strong>Manejo de Contexto Extendido:</strong> Capturan relaciones a largo plazo en el texto.</li>
<li><strong>Flexibilidad:</strong> Adaptables a diversas tareas de NLP.</li>
</ul>
<h3 id="63-aplicaciones-de-los-llm"><strong>6.3 Aplicaciones de los LLM</strong></h3>
<ul>
<li><strong>Asistentes Virtuales y Chatbots:</strong> Interacciones más naturales y contextuales.</li>
<li><strong>Traducción Automática:</strong> Mejoras en precisión y fluidez.</li>
<li><strong>Análisis de Sentimiento:</strong> Comprensión de percepciones del cliente en redes sociales.</li>
<li><strong>Generación de Contenido:</strong> Creación de resúmenes, artículos y textos personalizados.</li>
<li><strong>Educación y Tutoría Personalizada:</strong> Proporcionan explicaciones y apoyo en el aprendizaje.</li>
<li><strong>Salud:</strong> Ayuda en diagnóstico preliminar y asistencia al paciente.</li>
<li><strong>Programación:</strong> Generación de código y asistencia en desarrollo de software.</li>
</ul>
<h3 id="63-desafios-y-consideraciones-eticas"><strong>6.3 Desafíos y Consideraciones Éticas</strong></h3>
<ul>
<li><strong>Sesgos y Discriminación:</strong> Pueden heredar prejuicios de los datos de entrenamiento.</li>
<li><strong>Desinformación:</strong> Capacidad para generar información falsa de manera convincente.</li>
<li><strong>Privacidad de Datos:</strong> Riesgo de reproducir información sensible.</li>
<li><strong>Recursos Computacionales:</strong> Alto consumo de energía y recursos, impacto ambiental.</li>
<li><strong>Transparencia:</strong> Dificultad para entender y explicar las decisiones del modelo.</li>
</ul>
<h3 id="64-avances-y-tendencias-recientes"><strong>6.4 Avances y Tendencias Recientes</strong></h3>
<ul>
<li><strong>Fine-Tuning Específico:</strong> Ajuste de modelos para tareas o dominios específicos.</li>
<li><strong>Modelos Multimodales:</strong> Integración de texto con imágenes y audio.</li>
<li><strong>Eficiencia y Sostenibilidad:</strong> Investigación en arquitecturas más eficientes.</li>
<li><strong>Modelos Multilingües:</strong> Entrenamiento en múltiples idiomas para mayor accesibilidad.</li>
<li><strong>Aprendizaje Federado:</strong> Entrenamiento distribuido que mejora la privacidad.</li>
</ul>
<h3 id="65-impacto-en-la-sociedad-y-el-futuro"><strong>6.5 Impacto en la Sociedad y el Futuro</strong></h3>
<p>Los LLM tienen el potencial de transformar sectores como:</p>
<ul>
<li><strong>Educación:</strong> Personalización del aprendizaje y acceso a información.</li>
<li><strong>Salud:</strong> Asistencia en diagnósticos y tratamiento.</li>
<li><strong>Negocios:</strong> Automatización y mejora en atención al cliente.</li>
<li><strong>Investigación:</strong> Análisis y síntesis de grandes volúmenes de información.</li>
</ul>
<p><strong>Consideraciones Futuras:</strong></p>
<ul>
<li><strong>Regulación y Ética:</strong> Desarrollo de marcos para uso responsable.</li>
<li><strong>Accesibilidad:</strong> Democratización de la tecnología para evitar brechas.</li>
<li><strong>Interacción Humano-Máquina:</strong> Mejora en la comunicación y colaboración.</li>
</ul>
<h3 id="66-ejemplos-de-llm"><strong>6.6 Ejemplos de LLM</strong>:</h3>
<ul>
<li>
<p><strong>ChatGPT (OpenAI)</strong>: Es uno de los modelos más populares de OpenAI, basado en la arquitectura GPT (Generative Pre-trained Transformer). Se ha utilizado en diversas versiones como GPT-3 y GPT-4.</p>
</li>
<li>
<p><strong>Gemini (Google/Alphabet)</strong>: Este es el nombre de los modelos de lenguaje de Google, que anteriormente estaba representado por Bard o el modelo de lenguaje de PaLM. Google ha reestructurado su enfoque hacia LLM con su proyecto Gemini, parte de su división de inteligencia artificial DeepMind.</p>
</li>
<li>
<p><strong>Claude (Anthropic)</strong>: Claude es el modelo de lenguaje desarrollado por Anthropic, una empresa creada por antiguos miembros de OpenAI. Se centra en la seguridad y la alineación de los modelos de IA.</p>
</li>
<li>
<p><strong>Copilot (Microsoft)</strong>: Aunque Microsoft no desarrolla directamente su propio LLM, ha integrado modelos de OpenAI como GPT-4 en su ecosistema bajo el nombre de Copilot, que se utiliza en aplicaciones como Microsoft Word, Excel, y otras herramientas de productividad.</p>
</li>
<li>
<p><strong>LLaMA (Meta)</strong>: El modelo LLaMA (Large Language Model Meta AI) es el LLM de Meta (Facebook), diseñado para ser más eficiente en términos de capacidad y rendimiento.</p>
</li>
</ul>
<hr />
<h2 id="7-redes-neuronales-multimodales"><strong>7. Redes Neuronales Multimodales</strong></h2>
<h3 id="71-que-son-las-redes-neuronales-multimodales"><strong>7.1 ¿Qué son las Redes Neuronales Multimodales?</strong></h3>
<p>Las <strong>Redes Neuronales Multimodales</strong> son arquitecturas avanzadas de inteligencia artificial diseñadas para procesar y combinar múltiples <strong>modalidades de datos</strong> simultáneamente, como texto, imágenes, audio y video. Su objetivo es integrar información de diferentes fuentes para realizar tareas más complejas y contextuales que requieren una comprensión holística de los datos.</p>
<h3 id="72-caracteristicas-principales"><strong>7.2 Características Principales</strong></h3>
<ul>
<li><strong>Integración de Múltiples Modalidades:</strong> Capaces de manejar y fusionar distintos tipos de datos, permitiendo una comprensión más rica y completa.</li>
<li><strong>Espacios de Representación Comunes:</strong> Transforman diferentes modalidades en representaciones vectoriales compatibles que pueden ser comparadas y combinadas en un espacio de embeddings unificado.</li>
<li><strong>Mecanismos de Atención Multimodal:</strong> Utilizan mecanismos de atención para alinear y relacionar información de diferentes modalidades de manera efectiva.</li>
<li><strong>Flexibilidad Arquitectónica:</strong> Combinan diferentes tipos de redes neuronales, como <strong>Transformers</strong> para texto y <strong>Redes Convolucionales (CNN)</strong> para imágenes, adaptándose a las necesidades específicas de cada tarea.</li>
</ul>
<h3 id="73-arquitectura-y-funcionamiento"><strong>7.3 Arquitectura y Funcionamiento</strong></h3>
<h4 id="731-componentes-de-las-redes-multimodales"><strong>7.3.1 Componentes de las Redes Multimodales</strong></h4>
<ul>
<li><strong>Modelos de Texto:</strong> Utilizan arquitecturas basadas en <strong>Transformers</strong> para procesar y entender el lenguaje natural.</li>
<li><strong>Modelos de Imagen:</strong> Emplean <strong>Redes Neuronales Convolucionales (CNN)</strong> o arquitecturas de <strong>Transformers</strong> para extraer y comprender características visuales.</li>
<li><strong>Modelos de Audio:</strong> Incorporan redes especializadas para el procesamiento de señales de audio, como <strong>Redes Neuronales Recurrentes (RNN)</strong> o <strong>Transformers</strong> adaptados.</li>
<li><strong>Integración y Fusión:</strong> Las salidas de los distintos modelos se combinan en un espacio de representación común mediante capas de fusión que permiten la interacción entre las diferentes modalidades.</li>
</ul>
<h4 id="732-mecanismos-de-atencion-multimodal"><strong>7.3.2 Mecanismos de Atención Multimodal</strong></h4>
<p>Los mecanismos de atención permiten que la red enfoque su atención en partes relevantes de cada modalidad, alineando y relacionando información de manera contextual. Esto es crucial para tareas donde la relación entre modalidades es compleja, como en la generación de descripciones de imágenes o la respuesta a preguntas basadas en contenido visual.</p>
<h3 id="74-aplicaciones-de-las-redes-neuronales-multimodales"><strong>7.4 Aplicaciones de las Redes Neuronales Multimodales</strong></h3>
<p><strong>7.4.1 Descripción de Imágenes</strong></p>
<p>Generar descripciones textuales detalladas basadas en el contenido de una imagen. Esto es útil para mejorar la accesibilidad de contenido visual y para aplicaciones de generación de contenido automático.</p>
<p><strong>7.4.2 Generación de Imágenes a partir de Texto</strong></p>
<p>Crear imágenes realistas y detalladas a partir de descripciones textuales proporcionadas por el usuario. <strong>DALL·E</strong> de OpenAI es un ejemplo destacado de esta aplicación.</p>
<p><strong>7.4.3 Búsqueda Multimodal</strong></p>
<p>Realizar búsquedas que combinan texto e imágenes para obtener resultados más precisos y relevantes. Por ejemplo, buscar imágenes que correspondan a una descripción textual específica.</p>
<p><strong>7.4.4 Reconocimiento de Video y Audio</strong></p>
<p>Analizar y comprender contenido que involucra múltiples flujos de datos simultáneamente, como videos con subtítulos o transcripciones de audio.</p>
<p><strong>7.4.5 Asistentes Virtuales Avanzados</strong></p>
<p>Desarrollar asistentes que puedan interactuar de manera más rica y contextual, integrando comprensión de lenguaje natural con reconocimiento de imágenes o gestos.</p>
<h3 id="75-ejemplos-notables-de-redes-neuronales-multimodales"><strong>7.5 Ejemplos Notables de Redes Neuronales Multimodales</strong></h3>
<p><strong>7.5.1 CLIP (Contrastive Language-Image Pre-training)</strong></p>
<p>Desarrollado por <strong>OpenAI</strong>, CLIP puede relacionar imágenes y texto de manera efectiva, permitiendo clasificar imágenes basándose en descripciones textuales sin necesidad de entrenamiento específico para cada categoría.</p>
<p><strong>7.5.2 DALL·E</strong></p>
<p>También de <strong>OpenAI</strong>, DALL·E genera imágenes a partir de descripciones textuales detalladas, combinando capacidades de generación de texto e imagen para crear contenido visual innovador.</p>
<p><strong>7.5.3 GPT-4</strong>
También de <strong>OpenAI</strong>,  GPT-4, en su versión multimodal, puede procesar tanto entradas de texto como de imágenes. Esto permite, por ejemplo, que el modelo entienda y describa imágenes, analice gráficos, o explique el contenido visual que se le presenta. En el caso de las imágenes, puede responder preguntas basadas en lo que "ve".</p>
<h3 id="76-ventajas-de-las-redes-neuronales-multimodales"><strong>7.6 Ventajas de las Redes Neuronales Multimodales</strong></h3>
<ul>
<li><strong>Comprensión Holística:</strong> Integran información de múltiples fuentes, proporcionando una visión más completa y contextualizada.</li>
<li><strong>Mayor Flexibilidad:</strong> Pueden adaptarse a tareas que requieren la interacción de diferentes tipos de datos, como la creación de contenido creativo o la mejora de sistemas de búsqueda.</li>
<li><strong>Innovación en Aplicaciones Creativas:</strong> Facilitan la generación de contenido innovador y aplicaciones avanzadas en campos como el arte digital, la educación y la investigación.</li>
</ul>
<h3 id="77-desafios-de-las-redes-neuronales-multimodales"><strong>7.7 Desafíos de las Redes Neuronales Multimodales</strong></h3>
<ul>
<li><strong>Complejidad de Entrenamiento:</strong> Requieren grandes conjuntos de datos multimodales y altos recursos computacionales para el entrenamiento.</li>
<li><strong>Integración Efectiva de Modalidades:</strong> Lograr una alineación efectiva entre diferentes tipos de datos puede ser complicado y requiere técnicas avanzadas.</li>
<li><strong>Sesgos Multimodales:</strong> Los sesgos presentes en una modalidad pueden afectar la comprensión general del modelo, requiriendo mecanismos de mitigación de sesgos.</li>
<li><strong>Escalabilidad:</strong> Manejar y procesar múltiples tipos de datos de manera eficiente puede ser un desafío a medida que aumenta la complejidad de las tareas.</li>
<li><strong>Mayor Complejidad Arquitectónica:</strong> La integración de múltiples modalidades añade una capa adicional de complejidad en comparación con los LLM que manejan una sola modalidad.</li>
<li><strong>Requerimientos de Datos Multimodales:</strong> Necesitan conjuntos de datos que incluyan múltiples tipos de información, lo que puede ser más difícil de obtener y procesar.</li>
<li><strong>Interacción entre Modalidades:</strong> Asegurar una interacción efectiva y significativa entre diferentes tipos de datos requiere técnicas avanzadas de alineación y fusión.</li>
</ul>
<h3 id="78-conclusion"><strong>7.8 Conclusión</strong></h3>
<p>Las <strong>Redes Neuronales Multimodales</strong> representan una evolución significativa en el campo de la inteligencia artificial, permitiendo la integración y comprensión simultánea de múltiples tipos de datos. Esta capacidad de combinar diferentes modalidades de información abre nuevas posibilidades en diversas aplicaciones, desde la generación de contenido creativo hasta la mejora de sistemas de búsqueda y asistentes virtuales avanzados.</p>
<p>Aunque enfrentan desafíos en términos de complejidad de entrenamiento, integración de modalidades y gestión de sesgos, las ventajas que ofrecen en términos de comprensión holística y flexibilidad hacen que las redes multimodales sean una área de investigación y desarrollo prometedora. La continua innovación en arquitecturas y técnicas de fusión multimodal permitirá abordar estos desafíos, potenciando aún más el impacto de la inteligencia artificial en múltiples industrias.</p>
<hr />
<h2 id="8-procesamiento-de-lenguaje-natural-nlp-y-redes-neuronales"><strong>8. Procesamiento de Lenguaje Natural (NLP) y Redes Neuronales</strong></h2>
<p>Aunque <strong>NLP</strong> no es una red neuronal en sí misma, se apoya en diversas <strong>arquitecturas de redes neuronales</strong> para llevar a cabo sus tareas. A continuación, se detalla cómo se integran diferentes tipos de redes neuronales en el campo de NLP:</p>
<h3 id="redes-neuronales-feedforward-ff-en-nlp"><strong>Redes Neuronales Feedforward (FF) en NLP</strong></h3>
<ul>
<li><strong>Aplicación:</strong> Clasificación de texto (e.g., detección de spam, análisis de sentimientos).</li>
<li><strong>Descripción:</strong> Utilizadas para tareas donde se requiere una clasificación simple basada en las características extraídas del texto.</li>
</ul>
<h3 id="redes-neuronales-recurrentes-rnn-y-lstm-en-nlp"><strong>Redes Neuronales Recurrentes (RNN) y LSTM en NLP</strong></h3>
<ul>
<li><strong>Aplicación:</strong> Modelado de secuencias, generación de texto, traducción automática.</li>
<li><strong>Descripción:</strong> Capaces de manejar dependencias temporales en el texto, permitiendo una mejor comprensión del contexto.</li>
</ul>
<h3 id="arquitectura-de-transformadores-en-nlp"><strong>Arquitectura de Transformadores en NLP</strong></h3>
<ul>
<li><strong>Aplicación:</strong> Modelos de lenguaje grandes (LLM) como GPT, BERT, T5.</li>
<li><strong>Descripción:</strong> Utilizan mecanismos de atención para procesar secuencias de texto de manera más eficiente y efectiva, permitiendo un mayor manejo del contexto y la generación de texto coherente.</li>
</ul>
<h3 id="redes-generativas-antagonicas-gan-en-nlp"><strong>Redes Generativas Antagónicas (GAN) en NLP</strong></h3>
<ul>
<li><strong>Aplicación:</strong> Generación de texto realista, mejora de la calidad del texto generado.</li>
<li><strong>Descripción:</strong> Aunque menos comunes que en visión por computadora, las GAN pueden emplearse para generar texto variado y coherente.</li>
</ul>
<hr />
<h3 id="conclusion"><strong>Conclusión</strong></h3>
<p><strong>Procesamiento de Lenguaje Natural (NLP)</strong> es un campo esencial dentro de la inteligencia artificial que se apoya en diversas <strong>arquitecturas de redes neuronales</strong> para lograr una comprensión y generación de lenguaje humano efectiva. Aunque <strong>NLP</strong> no es una red neuronal en sí misma, su éxito se basa en la integración y aplicación de diferentes tipos de redes neuronales, desde <strong>Feedforward</strong> hasta <strong>Transformers</strong>, para abordar una amplia variedad de tareas lingüísticas.</p>
<p>Incluir una sección específica sobre <strong>NLP</strong> en tu documento ayudará a clarificar cómo este campo interactúa con las distintas arquitecturas de redes neuronales, proporcionando una visión más completa de las aplicaciones y tecnologías en inteligencia artificial.</p>
<hr />
<h2 id="9-ventajas-de-la-ia"><strong>9. Ventajas de la IA</strong></h2>
<h3 id="91-automatizacion"><strong>9.1 Automatización</strong></h3>
<p>La IA puede automatizar flujos de trabajo y procesos, o bien trabajar de forma autónoma e independiente de un equipo humano. Por ejemplo, puede ayudar a automatizar aspectos de la ciberseguridad supervisando y analizando continuamente el tráfico de red. Del mismo modo, una fábrica inteligente puede usar al mismo tiempo decenas de tipos distintos de IA, como robots que utilizan visión artificial para desplazarse por la planta de producción o inspeccionar productos en busca de defectos, que crean gemelos digitales, o que usan analítica en tiempo real para medir la eficiencia y los resultados.</p>
<h3 id="92-reduce-el-error-humano"><strong>9.2 Reduce el error humano</strong></h3>
<p>La IA puede eliminar los errores manuales en el procesamiento de datos, el análisis, el montaje en la fabricación y otras tareas a través de automatización y el uso de algoritmos que siguen siempre los mismos procesos.</p>
<h3 id="93-elimina-las-tareas-repetitivas"><strong>9.3 Elimina las tareas repetitivas</strong></h3>
<p>La inteligencia artificial puede usarse para llevar a cabo tareas repetitivas, lo que libera capital humano para centrarse en problemas de mayor impacto. La IA se puede utilizar para automatizar procesos, como verificar documentos, transcribir llamadas telefónicas o responder a preguntas sencillas de los clientes, como "¿A qué hora cerráis?". Los robots suelen usarse para llevar a cabo tareas "aburridas, sucias o peligrosas" en lugar de una persona. </p>
<h3 id="94-rapida-y-precisa"><strong>9.4 Rápida y precisa</strong></h3>
<p>La IA puede procesar más información más rápido que un humano, encontrar patrones y descubrir relaciones en los datos que la persona podría pasar por alto.</p>
<h3 id="94-disponibilidad-infinita"><strong>9.4 Disponibilidad infinita</strong></h3>
<p>La IA no está limitada por la hora del día, la necesidad de descansar ni otras obligaciones que tenemos las personas. Cuando se ejecutan en la nube, la IA y el aprendizaje automático pueden estar "siempre encendidos" y trabajar continuamente en las tareas asignadas. </p>
<h3 id="94-investigacion-y-desarrollo-agilizados"><strong>9.4 Investigación y desarrollo agilizados</strong></h3>
<p>La capacidad para analizar grandes cantidades de datos rápidamente puede optimizar la investigación y el desarrollo. Por ejemplo, la IA se ha utilizado para el modelado predictivo de posibles tratamientos farmacéuticos o para cuantificar el genoma humano. </p>
<h2 id="10-aplicaciones-practicas-de-la-ia"><strong>10. Aplicaciones Prácticas de la IA</strong></h2>
<p>La IA tiene aplicaciones prácticas en diversos campos, como:</p>
<ul>
<li><strong>Medicina</strong>: Diagnóstico por imagen, análisis de datos genéticos, descubrimiento de fármacos.</li>
<li><strong>Finanzas</strong>: Análisis de riesgos, detección de fraudes, trading algorítmico.</li>
<li><strong>Automoción</strong>: Vehículos autónomos, optimización de rutas.</li>
<li><strong>Atención al Cliente</strong>: Chatbots, asistentes virtuales.</li>
<li><strong>Industria del Entretenimiento</strong>: Recomendación de contenido en plataformas de streaming.</li>
</ul>
<hr />












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.sections", "content.code.annotate"], "search": "../assets/javascripts/workers/search.07f07601.min.js", "translations": {"clipboard.copied": "Copiado al portapapeles", "clipboard.copy": "Copiar al portapapeles", "search.result.more.one": "1 m\u00e1s en esta p\u00e1gina", "search.result.more.other": "# m\u00e1s en esta p\u00e1gina", "search.result.none": "No se encontraron documentos", "search.result.one": "1 documento encontrado", "search.result.other": "# documentos encontrados", "search.result.placeholder": "Teclee para comenzar b\u00fasqueda", "search.result.term.missing": "Falta", "select.version": "Seleccionar versi\u00f3n"}}</script>
    
    
      <script src="../assets/javascripts/bundle.56dfad97.min.js"></script>
      
    
  </body>
</html>